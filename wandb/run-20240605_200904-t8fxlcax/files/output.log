[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'seed' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'optimizer' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'model' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'data' was locked by 'sweep' (ignored update).
CONFIG
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 2059
â”œâ”€â”€ seed_eval
â”‚   â””â”€â”€ 2000
â”œâ”€â”€ seed_test
â”‚   â””â”€â”€ 3000
â”œâ”€â”€ device
â”‚   â””â”€â”€ cuda
â”œâ”€â”€ train
â”‚   â””â”€â”€ do: true
â”‚       do_save: false
â”‚       reset_every: null
â”‚       dtype: float32
â”‚       compile: false
â”‚       do_amp: false
â”‚       batch_size: 128
â”‚       grad_clip: 1.0
â”‚       iters: 100001
â”‚       samples: null
â”‚       log_every: 1000
â”‚       save_every: 100000
â”‚       save_path: ./out
â”‚       num_workers: 0
â”‚       do_early_stop: false
â”‚       early_stop_patience: 5
â”‚       early_stop_metric: loss
â”‚       early_stop_tol: 0.001
â”‚       early_stop_start_iter: 20000.2
â”‚       early_stop_acc: null
â”‚       parallel_loss: true
â”‚       merge_embeds: false
â”‚       merge_type: sum
â”‚       seed: 0
â”‚       interval: step
â”‚       monitor: val/accuracy_ignore_index
â”‚       mode: max
â”‚       ema: 0.0
â”‚       test: false
â”‚       debug: false
â”‚       ignore_warnings: false
â”‚       state:
â”‚         mode: null
â”‚         n_context: 0
â”‚         n_context_eval: 0
â”‚       ckpt: null
â”‚       disable_dataset: false
â”‚       validate_at_start: false
â”‚       pretrained_model_path: null
â”‚       pretrained_model_strict_load: true
â”‚       pretrained_model_state_hook:
â”‚         _name_: null
â”‚       post_init_hook:
â”‚         _name_: null
â”‚       layer_decay:
â”‚         _name_: null
â”‚         decay: 0.7
â”‚       global_batch_size: 32
â”‚
â”œâ”€â”€ eval
â”‚   â””â”€â”€ do: true
â”‚       split: both
â”‚       batch_size: 1
â”‚       every: 5000
â”‚       every_samples: null
â”‚       iters: 1000
â”‚
â”œâ”€â”€ scheduler
â”‚   â””â”€â”€ decay_lr: true
â”‚       warmup_iters: 20000.2
â”‚       lr_decay_iters: 100001
â”‚       min_lr: 0.0001
â”‚
â”œâ”€â”€ optimizer
â”‚   â””â”€â”€ lr: 0.001
â”‚       _name_: adamw
â”‚       weight_decay: 0
â”‚       betas:
â”‚       - 0.9
â”‚       - 0.95
â”‚
â”œâ”€â”€ log_level
â”‚   â””â”€â”€ info
â”œâ”€â”€ examples_to_log
â”‚   â””â”€â”€ 3
â”œâ”€â”€ log_batch_idx
â”‚   â””â”€â”€ [0, 1]
â”œâ”€â”€ wandb
â”‚   â””â”€â”€ project: icl-arch
â”‚
â”œâ”€â”€ save_checkpoints
â”‚   â””â”€â”€ False
â”œâ”€â”€ nl_icl
â”‚   â””â”€â”€ do: false
â”‚       checkpoint_path: null
â”‚       hf_path: null
â”‚       task: sentiment
â”‚       n_seeds: 10
â”‚       min_examples_per_class: 0
â”‚       max_examples_per_class: 9
â”‚       do_full_vocab: true
â”‚
â”œâ”€â”€ do_count_param_only
â”‚   â””â”€â”€ False
â”œâ”€â”€ model
â”‚   â””â”€â”€ _name_: safari
â”‚       d_model: 64
â”‚       n_layer: 12
â”‚       d_inner: 256
â”‚       vocab_size: 32000
â”‚       resid_dropout: 0.0
â”‚       embed_dropout: 0.1
â”‚       layer:
â”‚         _name_: hyena
â”‚         emb_dim: 5
â”‚         filter_order: 64
â”‚         local_order: 3
â”‚         l_max: 131074
â”‚         modulate: true
â”‚         w: 10
â”‚         lr: 0.0005
â”‚         wd: 0.0
â”‚         lr_pos_emb: 0.0
â”‚       max_seq_len: 4096
â”‚
â””â”€â”€ data
    â””â”€â”€ _name_: linear-regression
        curriculum:
          dims:
            start: 5
            end: 5
            inc: 1
            interval: 2000
          points_train:
            start: 32
            end: 32
            inc: 2
            interval: 2000
          points_val:
            start: 1024
            end: 1024
            inc: 2
            interval: 2000
        task: linear_regression
        data: gaussian
        task_kwargs: {}
        n_dims: 5
        train_noise: 0
        val_noise: 0
backbone.layers.0.mixer.out_proj.weight: 4096
backbone.layers.0.mixer.out_proj.bias: 64
backbone.layers.0.mixer.in_proj.weight: 12288
backbone.layers.0.mixer.in_proj.bias: 192
backbone.layers.0.mixer.short_filter.weight: 576
backbone.layers.0.mixer.short_filter.bias: 192
backbone.layers.0.mixer.filter_fn.bias: 64
backbone.layers.0.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.0.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.0.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.0.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.0.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.0.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.0.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.0.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.0.norm1.weight: 64
backbone.layers.0.norm1.bias: 64
backbone.layers.0.mlp.fc1.weight: 16384
backbone.layers.0.mlp.fc1.bias: 256
backbone.layers.0.mlp.fc2.weight: 16384
backbone.layers.0.mlp.fc2.bias: 64
backbone.layers.0.norm2.weight: 64
backbone.layers.0.norm2.bias: 64
backbone.layers.1.mixer.out_proj.weight: 4096
backbone.layers.1.mixer.out_proj.bias: 64
backbone.layers.1.mixer.in_proj.weight: 12288
backbone.layers.1.mixer.in_proj.bias: 192
backbone.layers.1.mixer.short_filter.weight: 576
backbone.layers.1.mixer.short_filter.bias: 192
backbone.layers.1.mixer.filter_fn.bias: 64
backbone.layers.1.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.1.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.1.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.1.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.1.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.1.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.1.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.1.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.1.norm1.weight: 64
backbone.layers.1.norm1.bias: 64
backbone.layers.1.mlp.fc1.weight: 16384
backbone.layers.1.mlp.fc1.bias: 256
backbone.layers.1.mlp.fc2.weight: 16384
backbone.layers.1.mlp.fc2.bias: 64
backbone.layers.1.norm2.weight: 64
backbone.layers.1.norm2.bias: 64
backbone.layers.2.mixer.out_proj.weight: 4096
backbone.layers.2.mixer.out_proj.bias: 64
backbone.layers.2.mixer.in_proj.weight: 12288
backbone.layers.2.mixer.in_proj.bias: 192
backbone.layers.2.mixer.short_filter.weight: 576
backbone.layers.2.mixer.short_filter.bias: 192
backbone.layers.2.mixer.filter_fn.bias: 64
backbone.layers.2.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.2.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.2.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.2.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.2.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.2.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.2.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.2.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.2.norm1.weight: 64
backbone.layers.2.norm1.bias: 64
backbone.layers.2.mlp.fc1.weight: 16384
backbone.layers.2.mlp.fc1.bias: 256
backbone.layers.2.mlp.fc2.weight: 16384
backbone.layers.2.mlp.fc2.bias: 64
backbone.layers.2.norm2.weight: 64
backbone.layers.2.norm2.bias: 64
backbone.layers.3.mixer.out_proj.weight: 4096
backbone.layers.3.mixer.out_proj.bias: 64
backbone.layers.3.mixer.in_proj.weight: 12288
backbone.layers.3.mixer.in_proj.bias: 192
backbone.layers.3.mixer.short_filter.weight: 576
backbone.layers.3.mixer.short_filter.bias: 192
backbone.layers.3.mixer.filter_fn.bias: 64
backbone.layers.3.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.3.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.3.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.3.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.3.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.3.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.3.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.3.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.3.norm1.weight: 64
backbone.layers.3.norm1.bias: 64
backbone.layers.3.mlp.fc1.weight: 16384
backbone.layers.3.mlp.fc1.bias: 256
backbone.layers.3.mlp.fc2.weight: 16384
backbone.layers.3.mlp.fc2.bias: 64
backbone.layers.3.norm2.weight: 64
backbone.layers.3.norm2.bias: 64
backbone.layers.4.mixer.out_proj.weight: 4096
backbone.layers.4.mixer.out_proj.bias: 64
backbone.layers.4.mixer.in_proj.weight: 12288
backbone.layers.4.mixer.in_proj.bias: 192
backbone.layers.4.mixer.short_filter.weight: 576
backbone.layers.4.mixer.short_filter.bias: 192
backbone.layers.4.mixer.filter_fn.bias: 64
backbone.layers.4.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.4.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.4.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.4.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.4.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.4.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.4.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.4.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.4.norm1.weight: 64
backbone.layers.4.norm1.bias: 64
backbone.layers.4.mlp.fc1.weight: 16384
backbone.layers.4.mlp.fc1.bias: 256
backbone.layers.4.mlp.fc2.weight: 16384
backbone.layers.4.mlp.fc2.bias: 64
backbone.layers.4.norm2.weight: 64
backbone.layers.4.norm2.bias: 64
backbone.layers.5.mixer.out_proj.weight: 4096
backbone.layers.5.mixer.out_proj.bias: 64
backbone.layers.5.mixer.in_proj.weight: 12288
backbone.layers.5.mixer.in_proj.bias: 192
backbone.layers.5.mixer.short_filter.weight: 576
backbone.layers.5.mixer.short_filter.bias: 192
backbone.layers.5.mixer.filter_fn.bias: 64
backbone.layers.5.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.5.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.5.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.5.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.5.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.5.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.5.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.5.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.5.norm1.weight: 64
backbone.layers.5.norm1.bias: 64
backbone.layers.5.mlp.fc1.weight: 16384
backbone.layers.5.mlp.fc1.bias: 256
backbone.layers.5.mlp.fc2.weight: 16384
backbone.layers.5.mlp.fc2.bias: 64
backbone.layers.5.norm2.weight: 64
backbone.layers.5.norm2.bias: 64
backbone.layers.6.mixer.out_proj.weight: 4096
backbone.layers.6.mixer.out_proj.bias: 64
backbone.layers.6.mixer.in_proj.weight: 12288
backbone.layers.6.mixer.in_proj.bias: 192
backbone.layers.6.mixer.short_filter.weight: 576
backbone.layers.6.mixer.short_filter.bias: 192
backbone.layers.6.mixer.filter_fn.bias: 64
backbone.layers.6.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.6.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.6.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.6.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.6.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.6.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.6.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.6.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.6.norm1.weight: 64
backbone.layers.6.norm1.bias: 64
backbone.layers.6.mlp.fc1.weight: 16384
backbone.layers.6.mlp.fc1.bias: 256
backbone.layers.6.mlp.fc2.weight: 16384
backbone.layers.6.mlp.fc2.bias: 64
backbone.layers.6.norm2.weight: 64
backbone.layers.6.norm2.bias: 64
backbone.layers.7.mixer.out_proj.weight: 4096
backbone.layers.7.mixer.out_proj.bias: 64
backbone.layers.7.mixer.in_proj.weight: 12288
backbone.layers.7.mixer.in_proj.bias: 192
backbone.layers.7.mixer.short_filter.weight: 576
backbone.layers.7.mixer.short_filter.bias: 192
backbone.layers.7.mixer.filter_fn.bias: 64
backbone.layers.7.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.7.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.7.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.7.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.7.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.7.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.7.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.7.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.7.norm1.weight: 64
backbone.layers.7.norm1.bias: 64
backbone.layers.7.mlp.fc1.weight: 16384
backbone.layers.7.mlp.fc1.bias: 256
backbone.layers.7.mlp.fc2.weight: 16384
backbone.layers.7.mlp.fc2.bias: 64
backbone.layers.7.norm2.weight: 64
backbone.layers.7.norm2.bias: 64
backbone.layers.8.mixer.out_proj.weight: 4096
backbone.layers.8.mixer.out_proj.bias: 64
backbone.layers.8.mixer.in_proj.weight: 12288
backbone.layers.8.mixer.in_proj.bias: 192
backbone.layers.8.mixer.short_filter.weight: 576
backbone.layers.8.mixer.short_filter.bias: 192
backbone.layers.8.mixer.filter_fn.bias: 64
backbone.layers.8.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.8.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.8.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.8.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.8.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.8.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.8.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.8.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.8.norm1.weight: 64
backbone.layers.8.norm1.bias: 64
backbone.layers.8.mlp.fc1.weight: 16384
backbone.layers.8.mlp.fc1.bias: 256
backbone.layers.8.mlp.fc2.weight: 16384
backbone.layers.8.mlp.fc2.bias: 64
backbone.layers.8.norm2.weight: 64
backbone.layers.8.norm2.bias: 64
backbone.layers.9.mixer.out_proj.weight: 4096
backbone.layers.9.mixer.out_proj.bias: 64
backbone.layers.9.mixer.in_proj.weight: 12288
backbone.layers.9.mixer.in_proj.bias: 192
backbone.layers.9.mixer.short_filter.weight: 576
backbone.layers.9.mixer.short_filter.bias: 192
backbone.layers.9.mixer.filter_fn.bias: 64
backbone.layers.9.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.9.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.9.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.9.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.9.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.9.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.9.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.9.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.9.norm1.weight: 64
backbone.layers.9.norm1.bias: 64
backbone.layers.9.mlp.fc1.weight: 16384
backbone.layers.9.mlp.fc1.bias: 256
backbone.layers.9.mlp.fc2.weight: 16384
backbone.layers.9.mlp.fc2.bias: 64
backbone.layers.9.norm2.weight: 64
backbone.layers.9.norm2.bias: 64
backbone.layers.10.mixer.out_proj.weight: 4096
backbone.layers.10.mixer.out_proj.bias: 64
backbone.layers.10.mixer.in_proj.weight: 12288
backbone.layers.10.mixer.in_proj.bias: 192
backbone.layers.10.mixer.short_filter.weight: 576
backbone.layers.10.mixer.short_filter.bias: 192
backbone.layers.10.mixer.filter_fn.bias: 64
backbone.layers.10.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.10.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.10.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.10.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.10.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.10.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.10.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.10.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.10.norm1.weight: 64
backbone.layers.10.norm1.bias: 64
backbone.layers.10.mlp.fc1.weight: 16384
backbone.layers.10.mlp.fc1.bias: 256
backbone.layers.10.mlp.fc2.weight: 16384
backbone.layers.10.mlp.fc2.bias: 64
backbone.layers.10.norm2.weight: 64
backbone.layers.10.norm2.bias: 64
backbone.layers.11.mixer.out_proj.weight: 4096
backbone.layers.11.mixer.out_proj.bias: 64
backbone.layers.11.mixer.in_proj.weight: 12288
backbone.layers.11.mixer.in_proj.bias: 192
backbone.layers.11.mixer.short_filter.weight: 576
backbone.layers.11.mixer.short_filter.bias: 192
backbone.layers.11.mixer.filter_fn.bias: 64
backbone.layers.11.mixer.filter_fn.implicit_filter.0.weight: 320
backbone.layers.11.mixer.filter_fn.implicit_filter.0.bias: 64
backbone.layers.11.mixer.filter_fn.implicit_filter.1.freq: 64
backbone.layers.11.mixer.filter_fn.implicit_filter.2.weight: 4096
backbone.layers.11.mixer.filter_fn.implicit_filter.2.bias: 64
backbone.layers.11.mixer.filter_fn.implicit_filter.4.weight: 4096
backbone.layers.11.mixer.filter_fn.implicit_filter.4.bias: 64
backbone.layers.11.mixer.filter_fn.implicit_filter.6.weight: 4096
backbone.layers.11.norm1.weight: 64
backbone.layers.11.norm1.bias: 64
backbone.layers.11.mlp.fc1.weight: 16384
backbone.layers.11.mlp.fc1.bias: 256
backbone.layers.11.mlp.fc2.weight: 16384
backbone.layers.11.mlp.fc2.bias: 64
backbone.layers.11.norm2.weight: 64
backbone.layers.11.norm2.bias: 64
backbone.ln_f.weight: 64
backbone.ln_f.bias: 64
n_params=764288
ignored=[('embedder.embedder.weight', 320), ('embedder.embedder.bias', 64), ('head.head.weight', 64)]
  0%|                                                                                                                                  | 0/100001 [00:00<?, ?it/s]
  0%|                                                                                                                                    | 0/1000 [00:00<?, ?it/s]
[[split=train]] train_iter: 0, batch_idx: 0, input: [[0.6724631190299988, -2.400009870529175, 0.3455061614513397, 0.5480261445045471, -0.7111261487007141], [2.8987808227539062, 0.0, 0.0, 0.0, 0.0], [0.14275112748146057, -0.7984437942504883, -0.42434749007225037, -0.5070681571960449, 0.37779757380485535], [0.5941888093948364, 0.0, 0.0, 0.0, 0.0], [0.18988056480884552, 0.8159309029579163, 2.492114305496216, 0.4521389305591583, -0.8088147044181824], [0.5824015140533447, 0.0, 0.0, 0.0, 0.0], [1.1277031898498535, -0.6596270799636841, -1.437281847000122, -1.1760475635528564, 0.22123658657073975], [1.7983826398849487, 0.0, 0.0, 0.0, 0.0], [-1.2551008462905884, -0.6732901334762573, -0.4023072421550751, -0.19438129663467407, 0.20169568061828613], [-0.3347209095954895, 0.0, 0.0, 0.0, 0.0]], target: [2.8987808227539062, 0.5941888093948364, 0.5824015140533447, 1.7983826398849487, -0.3347209095954895, 1.7118861675262451, -2.4734838008880615, -0.3487122058868408, -0.1563582420349121, -0.8171783685684204]
[[split=train]] train_iter: 0, batch_idx: 1, input: [[0.8504043817520142, -0.4907650053501129, 0.4415382146835327, 1.4217822551727295, -0.67848140001297], [-0.78244948387146, 0.0, 0.0, 0.0, 0.0], [0.9367096424102783, -0.3013991117477417, -1.3340580463409424, -0.9543071389198303, -2.55865740776062], [4.399680137634277, 0.0, 0.0, 0.0, 0.0], [-0.643886923789978, -0.1648871898651123, -0.39494428038597107, -0.2646312415599823, -0.8083371520042419], [0.5357469320297241, 0.0, 0.0, 0.0, 0.0], [0.4465298056602478, -0.028843386098742485, -0.3619844317436218, 0.04552118107676506, -0.8745675683021545], [1.1047195196151733, 0.0, 0.0, 0.0, 0.0], [2.6112732887268066, -0.7762706279754639, -0.7768701314926147, -3.1935019493103027, 0.3451113998889923], [6.15365743637085, 0.0, 0.0, 0.0, 0.0]], target: [-0.78244948387146, 4.399680137634277, 0.5357469320297241, 1.1047195196151733, 6.15365743637085, -0.4323367476463318, -2.32352876663208, -2.028951644897461, -1.9296170473098755, -2.228977680206299]

Error executing job with overrides: ['data=linear-regression', 'data.curriculum.dims.end=5', 'data.curriculum.points_train.end=32', 'data.curriculum.points_train.start=32', 'data.curriculum.points_val.end=1024', 'data.curriculum.points_val.start=1024', 'eval.every=5000', 'eval.iters=1000', 'model=hyena', 'model.d_model=64', 'model.max_seq_len=4096', 'model.n_layer=12', 'optimizer=adamw', 'optimizer.lr=0.001', 'optimizer.weight_decay=0', 'scheduler.decay_lr=True', 'seed=2059', 'train.batch_size=128', 'train.do_early_stop=False', 'train.iters=100001', 'train.log_every=1000', 'train.parallel_loss=True']
Traceback (most recent call last):
  File "/mnt/ceph_rbd/synth-icl/main.py", line 1679, in main
    train(
  File "/mnt/ceph_rbd/synth-icl/main.py", line 1314, in train
    train_iter, exit_training, best_eval_loss, best_eval_acc = train_loop(
  File "/mnt/ceph_rbd/synth-icl/main.py", line 936, in train_loop
    eval_log = evaluate(
  File "/root/anaconda3/envs/icl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/ceph_rbd/synth-icl/main.py", line 1395, in evaluate
    hidden_states = model(embeddings)  # [batch_size, seq_len, emb_dim]
  File "/root/anaconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/ceph_rbd/synth-icl/arch/safari/safari.py", line 658, in forward
    hidden_states = self.backbone(input_ids, position_ids=position_ids)
  File "/root/anaconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/ceph_rbd/synth-icl/arch/safari/safari.py", line 583, in forward
    hidden_states, residual = layer(hidden_states, residual)
  File "/root/anaconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/ceph_rbd/synth-icl/arch/safari/safari.py", line 349, in forward
    hidden_states = self.mixer(hidden_states, **mixer_kwargs)
  File "/root/anaconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/ceph_rbd/synth-icl/arch/safari/models/sequence/hyena.py", line 348, in forward
    uc = self.short_filter(u)[..., :l_filter]
  File "/root/anaconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/anaconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/root/anaconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: expected scalar type Half but found Float
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.