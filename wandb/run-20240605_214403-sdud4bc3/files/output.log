[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'seed' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'optimizer' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'model' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'data' was locked by 'sweep' (ignored update).
CONFIG
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 2059
â”œâ”€â”€ seed_eval
â”‚   â””â”€â”€ 2000
â”œâ”€â”€ seed_test
â”‚   â””â”€â”€ 3000
â”œâ”€â”€ device
â”‚   â””â”€â”€ cuda
â”œâ”€â”€ train
â”‚   â””â”€â”€ do: true
â”‚       do_save: false
â”‚       reset_every: null
â”‚       dtype: float32
â”‚       compile: false
â”‚       do_amp: false
â”‚       batch_size: 128
â”‚       grad_clip: 1.0
â”‚       iters: 100001
â”‚       samples: null
â”‚       log_every: 1000
â”‚       save_every: 100000
â”‚       save_path: ./out
â”‚       num_workers: 0
â”‚       do_early_stop: false
â”‚       early_stop_patience: 5
â”‚       early_stop_metric: loss
â”‚       early_stop_tol: 0.001
â”‚       early_stop_start_iter: 20000.2
â”‚       early_stop_acc: null
â”‚       parallel_loss: true
â”‚       merge_embeds: false
â”‚       merge_type: sum
â”‚
â”œâ”€â”€ eval
â”‚   â””â”€â”€ do: true
â”‚       split: both
â”‚       batch_size: 1
â”‚       every: 5000
â”‚       every_samples: null
â”‚       iters: 1000
â”‚
â”œâ”€â”€ scheduler
â”‚   â””â”€â”€ decay_lr: true
â”‚       warmup_iters: 20000.2
â”‚       lr_decay_iters: 100001
â”‚       min_lr: 0.0001
â”‚
â”œâ”€â”€ optimizer
â”‚   â””â”€â”€ lr: 0.001
â”‚       _name_: adamw
â”‚       weight_decay: 0
â”‚       betas:
â”‚       - 0.9
â”‚       - 0.95
â”‚
â”œâ”€â”€ log_level
â”‚   â””â”€â”€ info
â”œâ”€â”€ examples_to_log
â”‚   â””â”€â”€ 3
â”œâ”€â”€ log_batch_idx
â”‚   â””â”€â”€ [0, 1]
â”œâ”€â”€ wandb
â”‚   â””â”€â”€ project: icl-arch
â”‚
â”œâ”€â”€ save_checkpoints
â”‚   â””â”€â”€ False
â”œâ”€â”€ nl_icl
â”‚   â””â”€â”€ do: false
â”‚       checkpoint_path: null
â”‚       hf_path: null
â”‚       task: sentiment
â”‚       n_seeds: 10
â”‚       min_examples_per_class: 0
â”‚       max_examples_per_class: 9
â”‚       do_full_vocab: true
â”‚
â”œâ”€â”€ do_count_param_only
â”‚   â””â”€â”€ False
â”œâ”€â”€ model
â”‚   â””â”€â”€ _name_: mamba
â”‚       d_model: 64
â”‚       n_layer: 12
â”‚       norm_epsilon: 1.0e-05
â”‚       rms_norm: false
â”‚       fused_add_norm: false
â”‚       residual_in_fp32: false
â”‚       max_seq_len: 4096
â”‚
â””â”€â”€ data
    â””â”€â”€ _name_: gauss-mix-model
        num_classes: 2
        num_xy_pairs_train: 2
        num_xy_pairs_val: 1024
        dim: 16
{'seed': 2059, 'seed_eval': 2000, 'seed_test': 3000, 'device': 'cuda', 'train': {'do': True, 'do_save': False, 'reset_every': None, 'dtype': 'float32', 'compile': False, 'do_amp': False, 'batch_size': 128, 'grad_clip': 1.0, 'iters': 100001, 'samples': None, 'log_every': 1000, 'save_every': 100000, 'save_path': './out', 'num_workers': 0, 'do_early_stop': False, 'early_stop_patience': 5, 'early_stop_metric': 'loss', 'early_stop_tol': 0.001, 'early_stop_start_iter': '${scheduler.warmup_iters}', 'early_stop_acc': None, 'parallel_loss': True, 'merge_embeds': False, 'merge_type': 'sum'}, 'eval': {'do': True, 'split': 'both', 'batch_size': 1, 'every': 5000, 'every_samples': None, 'iters': 1000}, 'scheduler': {'decay_lr': True, 'warmup_iters': "${eval:'${train.iters} * 0.2'}", 'lr_decay_iters': '${train.iters}', 'min_lr': "${eval:'${optimizer.lr} / 10'}"}, 'optimizer': {'lr': 0.001, '_name_': 'adamw', 'weight_decay': 0, 'betas': [0.9, 0.95]}, 'log_level': 'info', 'examples_to_log': 3, 'log_batch_idx': [0, 1], 'wandb': {'project': 'icl-arch'}, 'save_checkpoints': False, 'nl_icl': {'do': False, 'checkpoint_path': None, 'hf_path': None, 'task': 'sentiment', 'n_seeds': 10, 'min_examples_per_class': 0, 'max_examples_per_class': 9, 'do_full_vocab': True}, 'do_count_param_only': False, 'model': {'_name_': 'mamba', 'd_model': 64, 'n_layer': 12, 'norm_epsilon': 1e-05, 'rms_norm': False, 'fused_add_norm': False, 'residual_in_fp32': False, 'max_seq_len': 4096}, 'data': {'_name_': 'gauss-mix-model', 'num_classes': 2, 'num_xy_pairs_train': 2, 'num_xy_pairs_val': 1024, 'dim': 16}}
torch.Size([128, 2])
torch.Size([128, 2, 16])