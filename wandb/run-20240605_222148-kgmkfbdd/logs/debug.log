2024-06-05 22:21:48,780 INFO    MainThread:112639 [wandb_setup.py:_flush():76] Current SDK version is 0.15.9
2024-06-05 22:21:48,780 INFO    MainThread:112639 [wandb_setup.py:_flush():76] Configure stats pid to 112639
2024-06-05 22:21:48,780 INFO    MainThread:112639 [wandb_setup.py:_flush():76] Loading settings from /root/.config/wandb/settings
2024-06-05 22:21:48,780 INFO    MainThread:112639 [wandb_setup.py:_flush():76] Loading settings from /mnt/ceph_rbd/synth-icl/wandb/settings
2024-06-05 22:21:48,780 WARNING MainThread:112639 [wandb_setup.py:_flush():76] Unknown environment variable: WANDB_SERVICE
2024-06-05 22:21:48,780 INFO    MainThread:112639 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'edin', 'project': 'gmm-extrapolate', 'sweep_id': 'ef3mhqg0', 'root_dir': '/mnt/ceph_rbd/synth-icl', 'run_id': 'kgmkfbdd', 'sweep_param_path': '/mnt/ceph_rbd/synth-icl/wandb/sweep-ef3mhqg0/config-kgmkfbdd.yaml'}
2024-06-05 22:21:48,780 INFO    MainThread:112639 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-06-05 22:21:48,780 INFO    MainThread:112639 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'main.py', 'program': '/mnt/ceph_rbd/synth-icl/main.py'}
2024-06-05 22:21:48,780 INFO    MainThread:112639 [wandb_init.py:_log_setup():524] Logging user logs to /mnt/ceph_rbd/synth-icl/wandb/run-20240605_222148-kgmkfbdd/logs/debug.log
2024-06-05 22:21:48,781 INFO    MainThread:112639 [wandb_init.py:_log_setup():525] Logging internal logs to /mnt/ceph_rbd/synth-icl/wandb/run-20240605_222148-kgmkfbdd/logs/debug-internal.log
2024-06-05 22:21:48,781 INFO    MainThread:112639 [wandb_init.py:init():564] calling init triggers
2024-06-05 22:21:48,781 INFO    MainThread:112639 [wandb_init.py:init():571] wandb.init called with sweep_config: {'data': 'gauss-mix-model', 'data.dim': 16, 'data.num_classes': 2, 'data.num_xy_pairs_train': 1, 'data.num_xy_pairs_val': 1024, 'eval.every': 5000, 'eval.iters': 1000, 'model': 'mamba', 'model.d_model': 64, 'model.max_seq_len': 4096, 'model.n_layer': 12, 'optimizer': 'adamw', 'optimizer.lr': 0.001, 'optimizer.weight_decay': 0, 'scheduler.decay_lr': True, 'seed': 2059, 'train.batch_size': 128, 'train.do_early_stop': False, 'train.iters': 100001, 'train.log_every': 1000, 'train.parallel_loss': True}
config: {}
2024-06-05 22:21:48,781 INFO    MainThread:112639 [wandb_init.py:init():613] starting backend
2024-06-05 22:21:48,781 INFO    MainThread:112639 [wandb_init.py:init():617] setting up manager
2024-06-05 22:21:48,790 INFO    MainThread:112639 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-06-05 22:21:48,792 INFO    MainThread:112639 [wandb_init.py:init():623] backend started and connected
2024-06-05 22:21:48,811 INFO    MainThread:112639 [wandb_run.py:_config_callback():1282] config_cb None None {'data': 'gauss-mix-model', 'data.dim': 16, 'data.num_classes': 2, 'data.num_xy_pairs_train': 1, 'data.num_xy_pairs_val': 1024, 'eval.every': 5000, 'eval.iters': 1000, 'model': 'mamba', 'model.d_model': 64, 'model.max_seq_len': 4096, 'model.n_layer': 12, 'optimizer': 'adamw', 'optimizer.lr': 0.001, 'optimizer.weight_decay': 0, 'scheduler.decay_lr': True, 'seed': 2059, 'train.batch_size': 128, 'train.do_early_stop': False, 'train.iters': 100001, 'train.log_every': 1000, 'train.parallel_loss': True}
2024-06-05 22:21:48,813 INFO    MainThread:112639 [wandb_init.py:init():714] updated telemetry
2024-06-05 22:21:48,819 INFO    MainThread:112639 [wandb_init.py:init():747] communicating run to backend with 60.0 second timeout
2024-06-05 22:21:49,151 INFO    MainThread:112639 [wandb_run.py:_on_init():2180] communicating current version
2024-06-05 22:21:49,217 INFO    MainThread:112639 [wandb_run.py:_on_init():2189] got version response upgrade_message: "wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-06-05 22:21:49,217 INFO    MainThread:112639 [wandb_init.py:init():798] starting run threads in backend
2024-06-05 22:21:52,535 INFO    MainThread:112639 [wandb_run.py:_console_start():2159] atexit reg
2024-06-05 22:21:52,536 INFO    MainThread:112639 [wandb_run.py:_redirect():2014] redirect: wrap_raw
2024-06-05 22:21:52,537 INFO    MainThread:112639 [wandb_run.py:_redirect():2079] Wrapping output streams.
2024-06-05 22:21:52,537 INFO    MainThread:112639 [wandb_run.py:_redirect():2104] Redirects installed.
2024-06-05 22:21:52,538 INFO    MainThread:112639 [wandb_init.py:init():839] run started, returning control to user process
2024-06-05 22:21:52,544 INFO    MainThread:112639 [wandb_run.py:_config_callback():1282] config_cb None None {'seed_eval': 2000, 'seed_test': 3000, 'device': 'cuda', 'train': {'do': True, 'do_save': False, 'reset_every': None, 'dtype': 'float32', 'compile': False, 'do_amp': False, 'batch_size': 128, 'grad_clip': 1.0, 'iters': 100001, 'samples': None, 'log_every': 1000, 'save_every': 100000, 'save_path': './out', 'num_workers': 0, 'do_early_stop': False, 'early_stop_patience': 5, 'early_stop_metric': 'loss', 'early_stop_tol': 0.001, 'early_stop_start_iter': 20000.2, 'early_stop_acc': None, 'parallel_loss': True, 'merge_embeds': False, 'merge_type': 'sum'}, 'eval': {'do': True, 'split': 'both', 'batch_size': 1, 'every': 5000, 'every_samples': None, 'iters': 1000}, 'scheduler': {'decay_lr': True, 'warmup_iters': 20000.2, 'lr_decay_iters': 100001, 'min_lr': 0.0001}, 'log_level': 'info', 'examples_to_log': 3, 'log_batch_idx': [0, 1], 'wandb': {'project': 'icl-arch'}, 'save_checkpoints': False, 'nl_icl': {'do': False, 'checkpoint_path': None, 'hf_path': None, 'task': 'sentiment', 'n_seeds': 10, 'min_examples_per_class': 0, 'max_examples_per_class': 9, 'do_full_vocab': True}, 'do_count_param_only': False}
