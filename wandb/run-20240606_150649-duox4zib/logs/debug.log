2024-06-06 15:06:49,106 INFO    MainThread:142575 [wandb_setup.py:_flush():76] Current SDK version is 0.15.9
2024-06-06 15:06:49,106 INFO    MainThread:142575 [wandb_setup.py:_flush():76] Configure stats pid to 142575
2024-06-06 15:06:49,106 INFO    MainThread:142575 [wandb_setup.py:_flush():76] Loading settings from /root/.config/wandb/settings
2024-06-06 15:06:49,106 INFO    MainThread:142575 [wandb_setup.py:_flush():76] Loading settings from /mnt/ceph_rbd/synth-icl/wandb/settings
2024-06-06 15:06:49,106 WARNING MainThread:142575 [wandb_setup.py:_flush():76] Unknown environment variable: WANDB_SERVICE
2024-06-06 15:06:49,107 INFO    MainThread:142575 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'edin', 'project': 'og-p_bursty', 'sweep_id': 'tsqqmp49', 'root_dir': '/mnt/ceph_rbd/synth-icl', 'run_id': 'duox4zib', 'sweep_param_path': '/mnt/ceph_rbd/synth-icl/wandb/sweep-tsqqmp49/config-duox4zib.yaml'}
2024-06-06 15:06:49,107 INFO    MainThread:142575 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-06-06 15:06:49,107 INFO    MainThread:142575 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'main.py', 'program': '/mnt/ceph_rbd/synth-icl/main.py'}
2024-06-06 15:06:49,107 INFO    MainThread:142575 [wandb_init.py:_log_setup():524] Logging user logs to /mnt/ceph_rbd/synth-icl/wandb/run-20240606_150649-duox4zib/logs/debug.log
2024-06-06 15:06:49,107 INFO    MainThread:142575 [wandb_init.py:_log_setup():525] Logging internal logs to /mnt/ceph_rbd/synth-icl/wandb/run-20240606_150649-duox4zib/logs/debug-internal.log
2024-06-06 15:06:49,107 INFO    MainThread:142575 [wandb_init.py:init():564] calling init triggers
2024-06-06 15:06:49,107 INFO    MainThread:142575 [wandb_init.py:init():571] wandb.init called with sweep_config: {'data': 'omniglot', 'data.seq_config.p_bursty': 1, 'eval.every': 5000, 'eval.iters': 1000, 'model': 'mamba', 'model.d_model': 64, 'model.max_seq_len': 64, 'model.n_layer': 12, 'optimizer': 'adamw', 'optimizer.betas': [0.9, 0.95], 'optimizer.lr': 0.0001, 'optimizer.weight_decay': 0, 'scheduler.decay_lr': True, 'seed': 2059, 'train.batch_size': 128, 'train.do_early_stop': False, 'train.iters': 100001, 'train.log_every': 1000, 'train.num_workers': 4, 'train.parallel_loss': False}
config: {}
2024-06-06 15:06:49,108 INFO    MainThread:142575 [wandb_init.py:init():613] starting backend
2024-06-06 15:06:49,108 INFO    MainThread:142575 [wandb_init.py:init():617] setting up manager
2024-06-06 15:06:49,116 INFO    MainThread:142575 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-06-06 15:06:49,119 INFO    MainThread:142575 [wandb_init.py:init():623] backend started and connected
2024-06-06 15:06:49,137 INFO    MainThread:142575 [wandb_run.py:_config_callback():1282] config_cb None None {'data': 'omniglot', 'data.seq_config.p_bursty': 1, 'eval.every': 5000, 'eval.iters': 1000, 'model': 'mamba', 'model.d_model': 64, 'model.max_seq_len': 64, 'model.n_layer': 12, 'optimizer': 'adamw', 'optimizer.betas': [0.9, 0.95], 'optimizer.lr': 0.0001, 'optimizer.weight_decay': 0, 'scheduler.decay_lr': True, 'seed': 2059, 'train.batch_size': 128, 'train.do_early_stop': False, 'train.iters': 100001, 'train.log_every': 1000, 'train.num_workers': 4, 'train.parallel_loss': False}
2024-06-06 15:06:49,139 INFO    MainThread:142575 [wandb_init.py:init():714] updated telemetry
2024-06-06 15:06:49,146 INFO    MainThread:142575 [wandb_init.py:init():747] communicating run to backend with 60.0 second timeout
2024-06-06 15:06:49,508 INFO    MainThread:142575 [wandb_run.py:_on_init():2180] communicating current version
2024-06-06 15:06:49,574 INFO    MainThread:142575 [wandb_run.py:_on_init():2189] got version response upgrade_message: "wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-06-06 15:06:49,574 INFO    MainThread:142575 [wandb_init.py:init():798] starting run threads in backend
2024-06-06 15:06:56,773 INFO    MainThread:142575 [wandb_run.py:_console_start():2159] atexit reg
2024-06-06 15:06:56,774 INFO    MainThread:142575 [wandb_run.py:_redirect():2014] redirect: wrap_raw
2024-06-06 15:06:56,774 INFO    MainThread:142575 [wandb_run.py:_redirect():2079] Wrapping output streams.
2024-06-06 15:06:56,775 INFO    MainThread:142575 [wandb_run.py:_redirect():2104] Redirects installed.
2024-06-06 15:06:56,775 INFO    MainThread:142575 [wandb_init.py:init():839] run started, returning control to user process
2024-06-06 15:06:56,781 INFO    MainThread:142575 [wandb_run.py:_config_callback():1282] config_cb None None {'seed_eval': 2000, 'seed_test': 3000, 'device': 'cuda', 'train': {'do': True, 'do_save': False, 'reset_every': None, 'dtype': 'float32', 'compile': False, 'do_amp': False, 'batch_size': 128, 'grad_clip': 1.0, 'iters': 100001, 'samples': None, 'log_every': 1000, 'save_every': 100000, 'save_path': './out', 'num_workers': 4, 'do_early_stop': False, 'early_stop_patience': 5, 'early_stop_metric': 'loss', 'early_stop_tol': 0.001, 'early_stop_start_iter': 20000.2, 'early_stop_acc': None, 'parallel_loss': False, 'merge_embeds': False, 'merge_type': 'sum'}, 'eval': {'do': True, 'split': 'both', 'batch_size': 1, 'every': 5000, 'every_samples': None, 'iters': 1000}, 'scheduler': {'decay_lr': True, 'warmup_iters': 20000.2, 'lr_decay_iters': 100001, 'min_lr': 1e-05}, 'log_level': 'info', 'examples_to_log': 3, 'log_batch_idx': [0, 1], 'wandb': {'project': 'icl-arch'}, 'save_checkpoints': False, 'nl_icl': {'do': False, 'checkpoint_path': None, 'hf_path': None, 'task': 'sentiment', 'n_seeds': 10, 'min_examples_per_class': 0, 'max_examples_per_class': 9, 'do_full_vocab': True}, 'do_count_param_only': False, 'embedder': {'example_encoding': 'resnet', 'flatten_superpixels': False, 'example_dropout_prob': 0.0, 'concatenate_labels': False, 'use_positional_encodings': False, 'positional_dropout_prob': 0.0}}
2024-06-06 15:07:12,601 INFO    MainThread:142575 [wandb_watch.py:watch():51] Watching
