[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'seed' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'optimizer' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'model' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'data' was locked by 'sweep' (ignored update).
CONFIG
├── seed
│   └── 2059
├── seed_eval
│   └── 2000
├── seed_test
│   └── 3000
├── device
│   └── cuda
├── train
│   └── do: true
│       do_save: false
│       reset_every: null
│       dtype: float32
│       compile: false
│       do_amp: false
│       batch_size: 128
│       grad_clip: 1.0
│       iters: 100001
│       samples: null
│       log_every: 1000
│       save_every: 100000
│       save_path: ./out
│       num_workers: 4
│       do_early_stop: false
│       early_stop_patience: 5
│       early_stop_metric: loss
│       early_stop_tol: 0.001
│       early_stop_start_iter: 20000.2
│       early_stop_acc: null
│       parallel_loss: false
│       merge_embeds: false
│       merge_type: sum
│
├── eval
│   └── do: true
│       split: both
│       batch_size: 1
│       every: 5000
│       every_samples: null
│       iters: 1000
│
├── scheduler
│   └── decay_lr: true
│       warmup_iters: 20000.2
│       lr_decay_iters: 100001
│       min_lr: 1.0e-05
│
├── optimizer
│   └── lr: 0.0001
│       _name_: adamw
│       weight_decay: 0
│       betas:
│       - 0.9
│       - 0.95
│
├── log_level
│   └── info
├── examples_to_log
│   └── 3
├── log_batch_idx
│   └── [0, 1]
├── wandb
│   └── project: icl-arch
│
├── save_checkpoints
│   └── False
├── nl_icl
│   └── do: false
│       checkpoint_path: null
│       hf_path: null
│       task: sentiment
│       n_seeds: 10
│       min_examples_per_class: 0
│       max_examples_per_class: 9
│       do_full_vocab: true
│
├── do_count_param_only
│   └── False
├── model
│   └── _name_: mamba
│       d_model: 64
│       n_layer: 12
│       norm_epsilon: 1.0e-05
│       rms_norm: false
│       fused_add_norm: false
│       residual_in_fp32: false
│       max_seq_len: 64
│
├── embedder
│   └── example_encoding: resnet
│       flatten_superpixels: false
│       example_dropout_prob: 0.0
│       concatenate_labels: false
│       use_positional_encodings: false
│       positional_dropout_prob: 0.0
│
└── data
    └── _name_: omniglot
        num_classes: null
        train_seqs: bursty
        eval_seqs: fewshot_holdout
        example_type: omniglot
        generator_config:
          n_rare_classes: 1603
          n_common_classes: 10
          n_holdout_classes: 10
          zipf_exponent: 0.0
          use_zipf_for_common_rare: false
          noise_scale: 0.0
          preserve_ordering_every_n: null
        omniglot_config:
          omniglot_split: all
          exemplars: all
          augment_images: false
        symbolic_config:
          dataset_size: 1000
        seq_config:
          seq_len: 9
          fs_shots: 4
          bursty_shots: 3
          ways: 2
          p_bursty: 1
          p_bursty_common: 0.0
          p_bursty_zipfian: 1.0
          p_fewshot: 0.1
          non_bursty_type: zipfian
          labeling_common: ordered
          labeling_rare: ordered
          randomly_generate_rare: false
          grouped: false
Files already downloaded and verified
Files already downloaded and verified
/root/anaconda3/envs/icl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
mamba.backbone.layers.0.mixer.A_log: 2048
mamba.backbone.layers.0.mixer.D: 128
mamba.backbone.layers.0.mixer.in_proj.weight: 16384
mamba.backbone.layers.0.mixer.conv1d.weight: 512
mamba.backbone.layers.0.mixer.conv1d.bias: 128
mamba.backbone.layers.0.mixer.x_proj.weight: 4608
mamba.backbone.layers.0.mixer.dt_proj.weight: 512
mamba.backbone.layers.0.mixer.dt_proj.bias: 128
mamba.backbone.layers.0.mixer.out_proj.weight: 8192
mamba.backbone.layers.0.norm.weight: 64
mamba.backbone.layers.1.mixer.A_log: 2048
mamba.backbone.layers.1.mixer.D: 128
mamba.backbone.layers.1.mixer.in_proj.weight: 16384
mamba.backbone.layers.1.mixer.conv1d.weight: 512
mamba.backbone.layers.1.mixer.conv1d.bias: 128
mamba.backbone.layers.1.mixer.x_proj.weight: 4608
mamba.backbone.layers.1.mixer.dt_proj.weight: 512
mamba.backbone.layers.1.mixer.dt_proj.bias: 128
mamba.backbone.layers.1.mixer.out_proj.weight: 8192
mamba.backbone.layers.1.norm.weight: 64
mamba.backbone.layers.2.mixer.A_log: 2048
mamba.backbone.layers.2.mixer.D: 128
mamba.backbone.layers.2.mixer.in_proj.weight: 16384
mamba.backbone.layers.2.mixer.conv1d.weight: 512
mamba.backbone.layers.2.mixer.conv1d.bias: 128
mamba.backbone.layers.2.mixer.x_proj.weight: 4608
mamba.backbone.layers.2.mixer.dt_proj.weight: 512
mamba.backbone.layers.2.mixer.dt_proj.bias: 128
mamba.backbone.layers.2.mixer.out_proj.weight: 8192
mamba.backbone.layers.2.norm.weight: 64
mamba.backbone.layers.3.mixer.A_log: 2048
mamba.backbone.layers.3.mixer.D: 128
mamba.backbone.layers.3.mixer.in_proj.weight: 16384
mamba.backbone.layers.3.mixer.conv1d.weight: 512
mamba.backbone.layers.3.mixer.conv1d.bias: 128
mamba.backbone.layers.3.mixer.x_proj.weight: 4608
mamba.backbone.layers.3.mixer.dt_proj.weight: 512
mamba.backbone.layers.3.mixer.dt_proj.bias: 128
mamba.backbone.layers.3.mixer.out_proj.weight: 8192
mamba.backbone.layers.3.norm.weight: 64
mamba.backbone.layers.4.mixer.A_log: 2048
mamba.backbone.layers.4.mixer.D: 128
mamba.backbone.layers.4.mixer.in_proj.weight: 16384
mamba.backbone.layers.4.mixer.conv1d.weight: 512
mamba.backbone.layers.4.mixer.conv1d.bias: 128
mamba.backbone.layers.4.mixer.x_proj.weight: 4608
mamba.backbone.layers.4.mixer.dt_proj.weight: 512
mamba.backbone.layers.4.mixer.dt_proj.bias: 128
mamba.backbone.layers.4.mixer.out_proj.weight: 8192
mamba.backbone.layers.4.norm.weight: 64
mamba.backbone.layers.5.mixer.A_log: 2048
mamba.backbone.layers.5.mixer.D: 128
mamba.backbone.layers.5.mixer.in_proj.weight: 16384
mamba.backbone.layers.5.mixer.conv1d.weight: 512
mamba.backbone.layers.5.mixer.conv1d.bias: 128
mamba.backbone.layers.5.mixer.x_proj.weight: 4608
mamba.backbone.layers.5.mixer.dt_proj.weight: 512
mamba.backbone.layers.5.mixer.dt_proj.bias: 128
mamba.backbone.layers.5.mixer.out_proj.weight: 8192
mamba.backbone.layers.5.norm.weight: 64
mamba.backbone.layers.6.mixer.A_log: 2048
mamba.backbone.layers.6.mixer.D: 128
mamba.backbone.layers.6.mixer.in_proj.weight: 16384
mamba.backbone.layers.6.mixer.conv1d.weight: 512
mamba.backbone.layers.6.mixer.conv1d.bias: 128
mamba.backbone.layers.6.mixer.x_proj.weight: 4608
mamba.backbone.layers.6.mixer.dt_proj.weight: 512
mamba.backbone.layers.6.mixer.dt_proj.bias: 128
mamba.backbone.layers.6.mixer.out_proj.weight: 8192
mamba.backbone.layers.6.norm.weight: 64
mamba.backbone.layers.7.mixer.A_log: 2048
mamba.backbone.layers.7.mixer.D: 128
mamba.backbone.layers.7.mixer.in_proj.weight: 16384
mamba.backbone.layers.7.mixer.conv1d.weight: 512
mamba.backbone.layers.7.mixer.conv1d.bias: 128
mamba.backbone.layers.7.mixer.x_proj.weight: 4608
mamba.backbone.layers.7.mixer.dt_proj.weight: 512
mamba.backbone.layers.7.mixer.dt_proj.bias: 128
mamba.backbone.layers.7.mixer.out_proj.weight: 8192
mamba.backbone.layers.7.norm.weight: 64
mamba.backbone.layers.8.mixer.A_log: 2048
mamba.backbone.layers.8.mixer.D: 128
mamba.backbone.layers.8.mixer.in_proj.weight: 16384
mamba.backbone.layers.8.mixer.conv1d.weight: 512
mamba.backbone.layers.8.mixer.conv1d.bias: 128
mamba.backbone.layers.8.mixer.x_proj.weight: 4608
mamba.backbone.layers.8.mixer.dt_proj.weight: 512
mamba.backbone.layers.8.mixer.dt_proj.bias: 128
mamba.backbone.layers.8.mixer.out_proj.weight: 8192
mamba.backbone.layers.8.norm.weight: 64
mamba.backbone.layers.9.mixer.A_log: 2048
mamba.backbone.layers.9.mixer.D: 128
mamba.backbone.layers.9.mixer.in_proj.weight: 16384
mamba.backbone.layers.9.mixer.conv1d.weight: 512
mamba.backbone.layers.9.mixer.conv1d.bias: 128
mamba.backbone.layers.9.mixer.x_proj.weight: 4608
mamba.backbone.layers.9.mixer.dt_proj.weight: 512
mamba.backbone.layers.9.mixer.dt_proj.bias: 128
mamba.backbone.layers.9.mixer.out_proj.weight: 8192
mamba.backbone.layers.9.norm.weight: 64
mamba.backbone.layers.10.mixer.A_log: 2048
mamba.backbone.layers.10.mixer.D: 128
mamba.backbone.layers.10.mixer.in_proj.weight: 16384
mamba.backbone.layers.10.mixer.conv1d.weight: 512
mamba.backbone.layers.10.mixer.conv1d.bias: 128
mamba.backbone.layers.10.mixer.x_proj.weight: 4608
mamba.backbone.layers.10.mixer.dt_proj.weight: 512
mamba.backbone.layers.10.mixer.dt_proj.bias: 128
mamba.backbone.layers.10.mixer.out_proj.weight: 8192
mamba.backbone.layers.10.norm.weight: 64
mamba.backbone.layers.11.mixer.A_log: 2048
mamba.backbone.layers.11.mixer.D: 128
mamba.backbone.layers.11.mixer.in_proj.weight: 16384
mamba.backbone.layers.11.mixer.conv1d.weight: 512
mamba.backbone.layers.11.mixer.conv1d.bias: 128
mamba.backbone.layers.11.mixer.x_proj.weight: 4608
mamba.backbone.layers.11.mixer.dt_proj.weight: 512
mamba.backbone.layers.11.mixer.dt_proj.bias: 128
mamba.backbone.layers.11.mixer.out_proj.weight: 8192
mamba.backbone.layers.11.norm.weight: 64
mamba.backbone.norm_f.weight: 64
n_params=392512
ignored=[('embedder.example_encoding.embedder.embedder.convolution.weight', 3136), ('embedder.example_encoding.embedder.embedder.normalization.weight', 64), ('embedder.example_encoding.embedder.embedder.normalization.bias', 64), ('embedder.example_encoding.encoder.stages.0.layers.0.shortcut.convolution.weight', 1024), ('embedder.example_encoding.encoder.stages.0.layers.0.shortcut.normalization.weight', 16), ('embedder.example_encoding.encoder.stages.0.layers.0.shortcut.normalization.bias', 16), ('embedder.example_encoding.encoder.stages.0.layers.0.layer.0.convolution.weight', 9216), ('embedder.example_encoding.encoder.stages.0.layers.0.layer.0.normalization.weight', 16), ('embedder.example_encoding.encoder.stages.0.layers.0.layer.0.normalization.bias', 16), ('embedder.example_encoding.encoder.stages.0.layers.0.layer.1.convolution.weight', 2304), ('embedder.example_encoding.encoder.stages.0.layers.0.layer.1.normalization.weight', 16), ('embedder.example_encoding.encoder.stages.0.layers.0.layer.1.normalization.bias', 16), ('embedder.example_encoding.encoder.stages.0.layers.1.layer.0.convolution.weight', 2304), ('embedder.example_encoding.encoder.stages.0.layers.1.layer.0.normalization.weight', 16), ('embedder.example_encoding.encoder.stages.0.layers.1.layer.0.normalization.bias', 16), ('embedder.example_encoding.encoder.stages.0.layers.1.layer.1.convolution.weight', 2304), ('embedder.example_encoding.encoder.stages.0.layers.1.layer.1.normalization.weight', 16), ('embedder.example_encoding.encoder.stages.0.layers.1.layer.1.normalization.bias', 16), ('embedder.example_encoding.encoder.stages.1.layers.0.shortcut.convolution.weight', 512), ('embedder.example_encoding.encoder.stages.1.layers.0.shortcut.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.1.layers.0.shortcut.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.1.layers.0.layer.0.convolution.weight', 4608), ('embedder.example_encoding.encoder.stages.1.layers.0.layer.0.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.1.layers.0.layer.0.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.1.layers.0.layer.1.convolution.weight', 9216), ('embedder.example_encoding.encoder.stages.1.layers.0.layer.1.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.1.layers.0.layer.1.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.1.layers.1.layer.0.convolution.weight', 9216), ('embedder.example_encoding.encoder.stages.1.layers.1.layer.0.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.1.layers.1.layer.0.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.1.layers.1.layer.1.convolution.weight', 9216), ('embedder.example_encoding.encoder.stages.1.layers.1.layer.1.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.1.layers.1.layer.1.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.2.layers.0.shortcut.convolution.weight', 1024), ('embedder.example_encoding.encoder.stages.2.layers.0.shortcut.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.2.layers.0.shortcut.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.2.layers.0.layer.0.convolution.weight', 9216), ('embedder.example_encoding.encoder.stages.2.layers.0.layer.0.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.2.layers.0.layer.0.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.2.layers.0.layer.1.convolution.weight', 9216), ('embedder.example_encoding.encoder.stages.2.layers.0.layer.1.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.2.layers.0.layer.1.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.2.layers.1.layer.0.convolution.weight', 9216), ('embedder.example_encoding.encoder.stages.2.layers.1.layer.0.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.2.layers.1.layer.0.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.2.layers.1.layer.1.convolution.weight', 9216), ('embedder.example_encoding.encoder.stages.2.layers.1.layer.1.normalization.weight', 32), ('embedder.example_encoding.encoder.stages.2.layers.1.layer.1.normalization.bias', 32), ('embedder.example_encoding.encoder.stages.3.layers.0.shortcut.convolution.weight', 2048), ('embedder.example_encoding.encoder.stages.3.layers.0.shortcut.normalization.weight', 64), ('embedder.example_encoding.encoder.stages.3.layers.0.shortcut.normalization.bias', 64), ('embedder.example_encoding.encoder.stages.3.layers.0.layer.0.convolution.weight', 18432), ('embedder.example_encoding.encoder.stages.3.layers.0.layer.0.normalization.weight', 64), ('embedder.example_encoding.encoder.stages.3.layers.0.layer.0.normalization.bias', 64), ('embedder.example_encoding.encoder.stages.3.layers.0.layer.1.convolution.weight', 36864), ('embedder.example_encoding.encoder.stages.3.layers.0.layer.1.normalization.weight', 64), ('embedder.example_encoding.encoder.stages.3.layers.0.layer.1.normalization.bias', 64), ('embedder.example_encoding.encoder.stages.3.layers.1.layer.0.convolution.weight', 36864), ('embedder.example_encoding.encoder.stages.3.layers.1.layer.0.normalization.weight', 64), ('embedder.example_encoding.encoder.stages.3.layers.1.layer.0.normalization.bias', 64), ('embedder.example_encoding.encoder.stages.3.layers.1.layer.1.convolution.weight', 36864), ('embedder.example_encoding.encoder.stages.3.layers.1.layer.1.normalization.weight', 64), ('embedder.example_encoding.encoder.stages.3.layers.1.layer.1.normalization.bias', 64), ('embedder.embs.weight', 103872), ('head.fc.weight', 103872), ('head.fc.bias', 1623)]
  0%|                                                                                                                                                                 | 0/100001 [00:00<?, ?it/s]
  0%|                                                                                                                                                                   | 0/1000 [00:00<?, ?it/s]

  0%|▏                                                                                                                                                        | 1/1000 [00:07<2:12:50,  7.98s/it]

  0%|▎                                                                                                                                                        | 2/1000 [00:25<3:43:10, 13.42s/it]