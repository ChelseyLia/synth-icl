wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'model' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'data' was locked by 'sweep' (ignored update).
CONFIG
├── seed
│   └── 2059
├── seed_eval
│   └── 2000
├── seed_test
│   └── 3000
├── device
│   └── cuda
├── train
│   └── do: true
│       do_save: false
│       reset_every: null
│       dtype: float32
│       compile: false
│       do_amp: false
│       batch_size: 128
│       grad_clip: 1.0
│       iters: 100001
│       samples: null
│       log_every: 1000
│       save_every: 100000
│       save_path: ./out
│       num_workers: 0
│       do_early_stop: false
│       early_stop_patience: 5
│       early_stop_metric: loss
│       early_stop_tol: 0.001
│       early_stop_start_iter: 20000.2
│       early_stop_acc: null
│       parallel_loss: true
│       merge_embeds: false
│       merge_type: sum
│
├── eval
│   └── do: true
│       split: both
│       batch_size: 1
│       every: 5000
│       every_samples: null
│       iters: 1000
│
├── scheduler
│   └── decay_lr: true
│       warmup_iters: 20000.2
│       lr_decay_iters: 100001
│       min_lr: 3.16228e-05
│
├── optimizer
│   └── lr: 0.000316228
│       _name_: adamw
│       weight_decay: 0
│       betas:
│       - 0.9
│       - 0.95
│
├── log_level
│   └── info
├── examples_to_log
│   └── 3
├── log_batch_idx
│   └── [0, 1]
├── wandb
│   └── project: icl-arch
│
├── save_checkpoints
│   └── False
├── nl_icl
│   └── do: false
│       checkpoint_path: null
│       hf_path: null
│       task: sentiment
│       n_seeds: 10
│       min_examples_per_class: 0
│       max_examples_per_class: 9
│       do_full_vocab: true
│
├── do_count_param_only
│   └── False
├── model
│   └── _name_: mamba
│       d_model: 64
│       n_layer: 12
│       norm_epsilon: 1.0e-05
│       rms_norm: false
│       fused_add_norm: false
│       residual_in_fp32: false
│       max_seq_len: 4096
│
└── data
    └── _name_: gauss-mix-model
        num_classes: 2
        num_xy_pairs_train: 32
        num_xy_pairs_val: 1024
        dim: 16
head.linear.weight: 128
head.linear.bias: 2
mamba.backbone.layers.0.mixer.A_log: 2048
mamba.backbone.layers.0.mixer.D: 128
mamba.backbone.layers.0.mixer.in_proj.weight: 16384
mamba.backbone.layers.0.mixer.conv1d.weight: 512
mamba.backbone.layers.0.mixer.conv1d.bias: 128
mamba.backbone.layers.0.mixer.x_proj.weight: 4608
mamba.backbone.layers.0.mixer.dt_proj.weight: 512
mamba.backbone.layers.0.mixer.dt_proj.bias: 128
mamba.backbone.layers.0.mixer.out_proj.weight: 8192
mamba.backbone.layers.0.norm.weight: 64
mamba.backbone.layers.1.mixer.A_log: 2048
mamba.backbone.layers.1.mixer.D: 128
mamba.backbone.layers.1.mixer.in_proj.weight: 16384
mamba.backbone.layers.1.mixer.conv1d.weight: 512
mamba.backbone.layers.1.mixer.conv1d.bias: 128
mamba.backbone.layers.1.mixer.x_proj.weight: 4608
mamba.backbone.layers.1.mixer.dt_proj.weight: 512
mamba.backbone.layers.1.mixer.dt_proj.bias: 128
mamba.backbone.layers.1.mixer.out_proj.weight: 8192
mamba.backbone.layers.1.norm.weight: 64
mamba.backbone.layers.2.mixer.A_log: 2048
mamba.backbone.layers.2.mixer.D: 128
mamba.backbone.layers.2.mixer.in_proj.weight: 16384
mamba.backbone.layers.2.mixer.conv1d.weight: 512
mamba.backbone.layers.2.mixer.conv1d.bias: 128
mamba.backbone.layers.2.mixer.x_proj.weight: 4608
mamba.backbone.layers.2.mixer.dt_proj.weight: 512
mamba.backbone.layers.2.mixer.dt_proj.bias: 128
mamba.backbone.layers.2.mixer.out_proj.weight: 8192
mamba.backbone.layers.2.norm.weight: 64
mamba.backbone.layers.3.mixer.A_log: 2048
mamba.backbone.layers.3.mixer.D: 128
mamba.backbone.layers.3.mixer.in_proj.weight: 16384
mamba.backbone.layers.3.mixer.conv1d.weight: 512
mamba.backbone.layers.3.mixer.conv1d.bias: 128
mamba.backbone.layers.3.mixer.x_proj.weight: 4608
mamba.backbone.layers.3.mixer.dt_proj.weight: 512
mamba.backbone.layers.3.mixer.dt_proj.bias: 128
mamba.backbone.layers.3.mixer.out_proj.weight: 8192
mamba.backbone.layers.3.norm.weight: 64
mamba.backbone.layers.4.mixer.A_log: 2048
mamba.backbone.layers.4.mixer.D: 128
mamba.backbone.layers.4.mixer.in_proj.weight: 16384
mamba.backbone.layers.5.mixer.conv1d.weight: 512
mamba.backbone.layers.5.mixer.conv1d.bias: 128
mamba.backbone.layers.5.mixer.x_proj.weight: 4608
mamba.backbone.layers.5.mixer.dt_proj.weight: 512
mamba.backbone.layers.5.mixer.dt_proj.bias: 128
mamba.backbone.layers.5.mixer.out_proj.weight: 8192
mamba.backbone.layers.5.norm.weight: 64
mamba.backbone.layers.6.mixer.A_log: 2048
mamba.backbone.layers.6.mixer.D: 128
mamba.backbone.layers.6.mixer.in_proj.weight: 16384
mamba.backbone.layers.6.mixer.conv1d.weight: 512
mamba.backbone.layers.6.mixer.conv1d.bias: 128
mamba.backbone.layers.6.mixer.x_proj.weight: 4608
mamba.backbone.layers.6.mixer.dt_proj.weight: 512
mamba.backbone.layers.6.mixer.dt_proj.bias: 128
mamba.backbone.layers.6.mixer.out_proj.weight: 8192
mamba.backbone.layers.6.norm.weight: 64
mamba.backbone.layers.7.mixer.A_log: 2048
mamba.backbone.layers.7.mixer.D: 128
mamba.backbone.layers.7.mixer.in_proj.weight: 16384
mamba.backbone.layers.7.mixer.conv1d.weight: 512
mamba.backbone.layers.7.mixer.conv1d.bias: 128
mamba.backbone.layers.7.mixer.x_proj.weight: 4608
mamba.backbone.layers.7.mixer.dt_proj.weight: 512
mamba.backbone.layers.7.mixer.dt_proj.bias: 128
mamba.backbone.layers.7.mixer.out_proj.weight: 8192
mamba.backbone.layers.7.norm.weight: 64
mamba.backbone.layers.8.mixer.A_log: 2048
mamba.backbone.layers.8.mixer.D: 128
mamba.backbone.layers.8.mixer.in_proj.weight: 16384
mamba.backbone.layers.8.mixer.conv1d.weight: 512
mamba.backbone.layers.8.mixer.conv1d.bias: 128
mamba.backbone.layers.8.mixer.x_proj.weight: 4608
mamba.backbone.layers.8.mixer.dt_proj.weight: 512
mamba.backbone.layers.8.mixer.dt_proj.bias: 128
mamba.backbone.layers.8.mixer.out_proj.weight: 8192
mamba.backbone.layers.8.norm.weight: 64
mamba.backbone.layers.9.mixer.A_log: 2048
mamba.backbone.layers.9.mixer.D: 128
mamba.backbone.layers.9.mixer.in_proj.weight: 16384
mamba.backbone.layers.9.mixer.conv1d.weight: 512
mamba.backbone.layers.9.mixer.conv1d.bias: 128
mamba.backbone.layers.9.mixer.x_proj.weight: 4608
mamba.backbone.layers.9.mixer.dt_proj.weight: 512
mamba.backbone.layers.9.mixer.dt_proj.bias: 128
mamba.backbone.layers.9.mixer.out_proj.weight: 8192
mamba.backbone.layers.9.norm.weight: 64
mamba.backbone.layers.10.mixer.A_log: 2048
mamba.backbone.layers.10.mixer.D: 128
mamba.backbone.layers.10.mixer.in_proj.weight: 16384
mamba.backbone.layers.10.mixer.conv1d.weight: 512
mamba.backbone.layers.10.mixer.conv1d.bias: 128
mamba.backbone.layers.10.mixer.x_proj.weight: 4608
mamba.backbone.layers.10.mixer.dt_proj.weight: 512
mamba.backbone.layers.10.mixer.dt_proj.bias: 128
mamba.backbone.layers.10.mixer.out_proj.weight: 8192
mamba.backbone.layers.10.norm.weight: 64
mamba.backbone.layers.11.mixer.A_log: 2048
mamba.backbone.layers.11.mixer.D: 128
mamba.backbone.layers.11.mixer.in_proj.weight: 16384
mamba.backbone.layers.11.mixer.conv1d.weight: 512
mamba.backbone.layers.11.mixer.conv1d.bias: 128
mamba.backbone.layers.11.mixer.x_proj.weight: 4608
mamba.backbone.layers.11.mixer.dt_proj.weight: 512
mamba.backbone.layers.11.mixer.dt_proj.bias: 128
mamba.backbone.layers.11.mixer.out_proj.weight: 8192
mamba.backbone.layers.11.norm.weight: 64
mamba.backbone.norm_f.weight: 64
n_params=392642
ignored=[('embedder.embedder.weight', 1024), ('embedder.embedder.bias', 64), ('embedder.y_embedder.weight', 32)]
[[split=train]] train_iter: 0, batch_idx: 0, input: [[-1.5143520832061768, 1.7547247409820557, 0.09696385264396667, -1.2768162488937378, -0.04301077127456665, 0.36145925521850586, 0.3306042551994324, -1.5219900608062744, 1.3302793502807617, -0.46433794498443604, 0.6675390601158142, 0.21871596574783325, -1.5362563133239746, -0.8872127532958984, 1.5057337284088135, 1.8132071495056152], [-1.6007181406021118, -0.4788353443145752, 0.028184544295072556, -0.3686429262161255, 0.42227551341056824, -1.725391149520874, 0.3964702785015106, -0.2967173457145691, -0.16716866195201874, 1.344051480293274, -0.18993142247200012, 0.35925912857055664, 1.2835932970046997, -0.7802431583404541, 0.13172271847724915, -0.09341850876808167], [-0.35537034273147583, -0.1103639006614685, 0.33140987157821655, -0.02055203914642334, -0.04400321841239929, -1.6546485424041748, 2.5007529258728027, 0.07875090837478638, 0.10718464851379395, -1.8070284128189087, -1.1343684196472168, -0.4570884108543396, 0.8277196884155273, 0.9047274589538574, 3.121223211288452, 0.16567355394363403], [-0.8045891523361206, -0.8511910438537598, 0.6067851781845093, -0.5601234436035156, 1.332539677619934, 0.1546824872493744, 0.43413957953453064, -0.8006095290184021, -1.2939538955688477, -0.4800732433795929, -1.2939326763153076, -0.25739020109176636, -0.4092409312725067, -0.11367404460906982, 2.330000877380371, 0.20296554267406464], [-1.0687131881713867, 0.706230640411377, -1.0980255603790283, -0.13915877044200897, 1.3317065238952637, -1.7027397155761719, 0.510585367679596, -1.5370551347732544, 1.2595176696777344, -0.5114614963531494, -0.5539270043373108, -1.6019115447998047, -1.5422594547271729, -0.26837268471717834, -1.0594700574874878, -1.7739094495773315], [-0.398430734872818, 1.0732274055480957, -1.3770229816436768, -0.6845036745071411, 0.7048077583312988, -2.234358310699463, 1.8881504535675049, -0.33293473720550537, 3.0147624015808105, 0.19990605115890503, -0.4215734004974365, -0.9246740937232971, -1.8692293167114258, -0.7289865016937256, 1.518053412437439, -1.7225006818771362], [0.5087490677833557, -0.27192652225494385, -0.5404969453811646, 0.12042433023452759, -0.5628848075866699, 1.1719857454299927, -0.07389097660779953, -0.9998555183410645, -1.8671907186508179, 0.7057558298110962, 0.9212816953659058, -2.0275697708129883, -0.983529269695282, -1.0170090198516846, 0.5701295137405396, -1.6484602689743042], [-1.0813016891479492, 1.8321754932403564, -1.1518560647964478, -1.567870855331421, 2.8022360801696777, -0.6278398036956787, -1.933232069015503, -2.028719902038574, 0.3994002640247345, -0.31433019042015076, -1.6483817100524902, -0.2417345643043518, 0.3052675127983093, 0.989896297454834, -0.1778598129749298, 1.5500245094299316], [2.0347015857696533, -0.280759334564209, -0.7172321081161499, -3.697732925415039, 0.8875159621238708, 0.4868937134742737, 0.26461535692214966, -1.9957009553909302, 0.6421357989311218, -0.6392039060592651, -1.682052493095398, -1.2370362281799316, -0.2352406084537506, 0.8327987790107727, 2.0572502613067627, 0.6041803956031799], [1.6654763221740723, 1.3821427822113037, 1.4638192653656006, 0.2219933271408081, 0.9098039865493774, 0.2657618224620819, -0.6461665630340576, -1.2348071336746216, 1.6244637966156006, -1.9784942865371704, 2.712327480316162, -0.3420243561267853, -0.705276370048523, 0.42920705676078796, -0.5940912961959839, 0.9308212995529175]], target: [1, 1, 1, 1, 0, 0, 0, 0, 1, 1]
  0%|          | 0/100001 [00:00<?, ?it/s]

















































































































































































































  0%|          | 1/1000 [00:00<08:07,  2.05it/s]
[[split=eval]] train_iter: 0, eval_iter: 1, batch_idx: 0, input: [[1.6824767589569092, -0.12416306138038635, -0.39783143997192383, -0.9760239720344543, -0.15463939309120178, 2.1428475379943848, 1.1680240631103516, 1.3513710498809814, -0.1208442896604538, 1.5621721744537354, -0.13981181383132935, 0.35819166898727417, -1.1022169589996338, -0.6262861490249634, 1.307867169380188, -0.7538597583770752], [-0.4396413564682007, -0.13088947534561157, 2.279472827911377, 0.7285913228988647, -0.18801945447921753, 0.5439978241920471, 1.8616772890090942, -1.6721305847167969, -0.5496948957443237, -2.0170722007751465, 1.2243692874908447, 1.166947364807129, -1.2834309339523315, 1.3606278896331787, 0.004647254943847656, 0.8151227235794067], [-0.6282798647880554, -0.9466968178749084, -0.19374972581863403, 0.21524173021316528, -1.2082502841949463, 0.24866101145744324, -0.20498740673065186, -1.485066533088684, 0.6492854356765747, -0.354356586933136, -0.9295142889022827, 1.1462827920913696, 1.2443429231643677, 0.5073676109313965, 0.8979353904724121, 0.6268912553787231], [-1.190969467163086, -0.2856691777706146, 0.40201902389526367, -0.17508918046951294, 0.7688766717910767, -0.040345922112464905, -0.29841434955596924, -0.04809737205505371, 0.6213723421096802, 3.17270565032959, -0.46021556854248047, 1.1313927173614502, 0.9002565145492554, -0.8586390614509583, 1.4293572902679443, -0.6907442212104797], [-0.4833407402038574, -1.3059442043304443, -0.8889410495758057, -0.7153687477111816, 1.4219502210617065, -0.02365995943546295, -0.23268556594848633, 0.6895418763160706, -0.016207978129386902, 2.1645240783691406, 0.3754291236400604, 0.9294005632400513, 1.666422963142395, -1.2401286363601685, -0.30211302638053894, 0.7862509489059448], [0.05384527146816254, -1.2888144254684448, -0.17001231014728546, -1.33046293258667, -0.9807424545288086, 1.2584822177886963, -0.35376083850860596, 0.5468395352363586, -0.7697172164916992, 0.662036657333374, 2.1297590732574463, 0.45774102210998535, 1.7900904417037964, -0.8989505171775818, -0.20030628144741058, 0.1804753541946411], [-0.665522575378418, 2.247537136077881, 1.7118176221847534, 0.04235875606536865, -0.02132245898246765, 1.3925786018371582, -1.0391358137130737, -0.8686542510986328, -1.420846700668335, -0.5593845844268799, -0.3209126591682434, 1.1964056491851807, 0.36330533027648926, 0.718058705329895, 2.4453392028808594, 0.4590986371040344], [-1.4135910272598267, 0.17099326848983765, 2.519775152206421, -0.6016767024993896, -0.8035529851913452, -0.06561821699142456, -1.2507655620574951, -1.539149284362793, -0.6375802159309387, -0.34569960832595825, 1.013785481452942, 1.9759315252304077, -2.1224770545959473, -0.4506261348724365, 0.4761744737625122, 1.9395430088043213], [0.5925204157829285, -2.144406795501709, -0.599504828453064, 0.39349526166915894, -0.17187631130218506, 1.3166354894638062, -0.2339237928390503, -1.608883023262024, 0.7071664333343506, -0.42633509635925293, -0.7036190032958984, 0.36698317527770996, 1.2134020328521729, 1.199072241783142, -0.5205054879188538, -2.699526786804199], [0.683349072933197, 0.5220487117767334, 1.8973203897476196, -1.4434540271759033, 1.2910761833190918, 0.5457519888877869, -0.5402352213859558, -1.8815747499465942, 0.08863699436187744, -0.44318655133247375, -2.0760345458984375, -1.4156997203826904, 0.9976913928985596, 0.4235273003578186, 0.7454603314399719, 0.21489526331424713]], target: [1, 0, 1, 1, 1, 1, 0, 0, 1, 0]
[[split=eval]] train_iter: 0, eval_iter: 2, batch_idx: 0, input: [[0.47057589888572693, 1.0453990697860718, 0.7799639105796814, 1.4670612812042236, -1.004331111907959, -0.6577329635620117, 0.6159999370574951, -2.499952793121338, 1.2975283861160278, -0.6650038957595825, -0.8484234809875488, 0.9303284287452698, -0.016810685396194458, 0.4156733453273773, -3.3079380989074707, 0.4086337983608246], [0.25708696246147156, 2.675304651260376, 0.8875587582588196, -2.2268013954162598, -0.9204819202423096, 2.549546241760254, -3.6419289112091064, 0.4768978953361511, -0.17534354329109192, 1.3731226921081543, -0.8514416217803955, 1.568596601486206, -1.0735492706298828, 2.4051268100738525, 0.07487505674362183, -0.38028770685195923], [1.8733606338500977, -0.4261860251426697, -0.5036522150039673, -1.0998501777648926, -0.9914464354515076, 2.006800889968872, 0.992652177810669, 2.7157938480377197, -0.7564167976379395, 0.029668718576431274, -2.652165412902832, -0.910112738609314, -1.3523750305175781, 0.3172455132007599, 1.6650924682617188, -1.2582674026489258], [0.6677100658416748, -0.1215355396270752, -0.33804118633270264, -0.43749794363975525, -1.2375872135162354, 0.2618579566478729, 2.3156964778900146, -1.3801873922348022, 0.1666378378868103, -0.7338532209396362, 0.5030362606048584, -1.1081254482269287, -0.7412188053131104, 0.8544535636901855, 0.33864277601242065, 0.6314353346824646], [1.9103176593780518, 1.7395304441452026, 0.5818004608154297, 0.5297049880027771, -0.3098129332065582, 1.0190495252609253, 0.45367100834846497, -0.09298849105834961, 0.28892871737480164, 0.12463907897472382, 0.5580592751502991, -0.42145776748657227, -0.6365458965301514, 1.9641467332839966, -0.30824118852615356, 0.9709011316299438], [1.9299838542938232, 1.249228835105896, -1.6499534845352173, -0.032438457012176514, -0.5388146042823792, -0.19738763570785522, -0.2835479974746704, 0.2916741371154785, 0.32900136709213257, -0.6382647752761841, -0.7522316575050354, 1.5596342086791992, 1.5331670045852661, 0.8616737127304077, 1.5118529796600342, -0.628800094127655], [1.5487124919891357, 1.1517913341522217, 1.693795919418335, -2.0249853134155273, -0.03928665071725845, 1.2177414894104004, -0.05301302671432495, -0.04260891675949097, -0.08748728036880493, -1.0317955017089844, -1.0846858024597168, 1.48045814037323, 0.38850975036621094, 1.6706113815307617, 1.0856071710586548, -2.0274128913879395], [-0.01938045024871826, 0.6889207363128662, -0.07940447330474854, -0.5894602537155151, 1.88111412525177, 0.825320303440094, -0.1965453028678894, 0.03819821774959564, 0.9532728791236877, 2.0861411094665527, -0.5716025829315186, 1.072373628616333, 1.3933721780776978, 0.5401817560195923, -2.1804208755493164, 0.9858068823814392], [-2.0109572410583496, 0.6612741947174072, 0.6167154312133789, -1.013810634613037, -1.773553729057312, 0.5595917105674744, 1.343824863433838, -0.35612952709198, 0.5626485347747803, 0.7108691930770874, -2.0023882389068604, -0.3290393352508545, -0.5863395929336548, 1.0768996477127075, 1.064537763595581, -2.6043617725372314], [1.2423559427261353, 0.05670442804694176, 0.8657310009002686, -0.19591934978961945, -0.4169301390647888, 0.8103101253509521, -0.6972014904022217, -1.4146696329116821, 1.1655470132827759, 1.1795073747634888, -0.8061690330505371, -0.8809331655502319, 2.038125514984131, 1.0878634452819824, 0.1802406907081604, 1.2148354053497314]], target: [0, 1, 1, 0, 0, 1, 1, 0, 1, 0]
[[split=test]] train_iter: 0, eval_iter: 0, batch_idx: 0, input: [[-0.43552887439727783, 0.007368683815002441, 0.9478849172592163, -0.31263870000839233, -0.9897385835647583, -1.205442190170288, -0.7513461709022522, 1.103174090385437, 0.9361937046051025, -0.8696761727333069, -1.630163550376892, 1.9312785863876343, -0.20641553401947021, 0.18888181447982788, 1.0874388217926025, -0.1385347843170166], [-1.9605149030685425, 1.172332525253296, -1.4269548654556274, 0.19389784336090088, -3.175872802734375, -0.4173201024532318, 0.642121434211731, 1.5882281064987183, -0.34346675872802734, 0.9081318378448486, -0.0165480375289917, -0.9770034551620483, -1.701245903968811, -0.8829474449157715, 1.257362723350525, -1.7227863073349], [-1.088587760925293, -0.5580098628997803, 0.31924283504486084, 0.6274278163909912, 0.36994147300720215, -0.1033543050289154, -0.7732261419296265, -1.2422997951507568, -1.3892855644226074, -0.19667208194732666, 1.583243489265442, -0.27038583159446716, 1.145339012145996, 0.6084104776382446, -0.17359846830368042, -1.9872781038284302], [0.8624252080917358, 1.3701879978179932, -0.695002555847168, -0.9853690266609192, 0.10474914312362671, -1.6088947057724, 1.5651723146438599, 0.42931580543518066, -0.5416683554649353, -1.3649365901947021, -1.1327390670776367, -1.5075445175170898, -0.6070929169654846, -0.23605066537857056, -1.9595997333526611, -0.7422559857368469], [-0.9177008867263794, 0.6220269203186035, -0.9179106950759888, -0.8134156465530396, 0.32924723625183105, 0.15889114141464233, 1.3348692655563354, 2.931715965270996, -0.8676770329475403, -0.5756317377090454, 0.9961751699447632, 1.7585725784301758, -0.4013129770755768, 0.9719115495681763, 1.2936747074127197, 0.08600002527236938], [0.427041620016098, 0.3051919639110565, 0.6010592579841614, -1.5049166679382324, -0.8444578647613525, -0.5143827199935913, -0.6336992979049683, -0.09216731786727905, -1.1288847923278809, 0.14662182331085205, -1.0004985332489014, 0.3356902599334717, -0.5815561413764954, 0.983244001865387, 0.31037652492523193, 0.3704404830932617], [-0.42014142870903015, 0.4509637653827667, -0.08800512552261353, -0.5808945894241333, 0.8874462842941284, 0.5023048520088196, -0.4323524236679077, -0.7298206090927124, -0.06657430529594421, -0.3409428596496582, 0.7041586637496948, 0.8434913158416748, 0.9523489475250244, -1.346022129058838, 0.44869881868362427, -0.7485777139663696], [-0.6954530477523804, 0.6675150394439697, -0.1355365812778473, -0.9034574627876282, -1.0502365827560425, -0.9277742505073547, 0.4150370955467224, 0.5212050676345825, 0.11565180122852325, 0.270282506942749, -1.115786075592041, 0.11528551578521729, -1.3709862232208252, -0.6924203038215637, -0.5693349838256836, 1.627614140510559], [-0.8549790978431702, -0.08155268430709839, -1.1403653621673584, -1.7340024709701538, -1.1313362121582031, -0.6353355050086975, 0.2696617841720581, -1.2190303802490234, -0.730815589427948, 1.597952127456665, -2.7989354133605957, 2.0146875381469727, -0.8760677576065063, -0.8845603466033936, 0.7824171781539917, 2.9127044677734375], [-1.8245595693588257, 1.4447064399719238, 0.7922065258026123, 0.7023812532424927, -0.9940148591995239, 0.929895281791687, -0.19951513409614563, 1.1609070301055908, 0.8955879211425781, -1.3602713346481323, 0.23615765571594238, 0.828216552734375, -1.0216871500015259, -0.09650030732154846, -0.6681953072547913, -0.114205002784729]], target: [1, 1, 0, 0, 1, 0, 1, 1, 1, 1]

  1%|          | 6/1000 [00:02<06:40,  2.48it/s]






































































































































eval-test: {'loss': 0.72607421875, 'last_loss': 0.73193359375, 'avg_acc': 0.49779006838798523, 'acc': 0.49000000953674316}
best_test_acc: 0.49000000953674316
best_test_acc_train_iter: 0
patience_left: 5
best_test_loss: 0.72607421875
best_test_loss_train_iter: 0
train iter 0
loss: 0.7261354923248291
lr: 0.0

  0%|          | 5/100001 [12:29<1808:18:21, 65.10s/it]


















































































































































































































  1%|          | 1000/100001 [19:34<30:41:15,  1.12s/it]train iter 1000
loss: 0.6933894753456116
lr: 1.5811241887581123e-05


















































































































































































































  2%|▏         | 2000/100001 [26:41<30:50:02,  1.13s/it]train iter 2000
loss: 0.6916137933731079
lr: 3.162248377516225e-05



















































































































































































































  3%|▎         | 3000/100001 [33:48<28:41:43,  1.06s/it]train iter 3000
loss: 0.6046464443206787
lr: 4.743372566274337e-05


















































































































































































































  4%|▍         | 4000/100001 [40:55<30:17:34,  1.14s/it]train iter 4000
loss: 0.36443009972572327
lr: 6.32449675503245e-05



















































































































































































































  5%|▍         | 5000/100001 [48:05<24:21:50,  1.08it/s]
  0%|          | 1/1000 [00:00<05:00,  3.32it/s]



































































































































































































  0%|          | 4/1000 [00:01<06:40,  2.49it/s]



















































































































































































































eval-test: {'loss': 0.42724609375, 'last_loss': 0.477294921875, 'avg_acc': 0.8088926076889038, 'acc': 0.7870000600814819}
best_test_acc: 0.7870000600814819
best_test_acc_train_iter: 5000
patience_left: 5
best_test_loss: 0.42724609375
best_test_loss_train_iter: 5000
train iter 5000
loss: 0.34057602286338806
lr: 7.905620943790561e-05
  5%|▌         | 5001/100001 [1:01:50<6549:52:01, 248.21s/it]

























































































































































































































































































































































  6%|▌         | 6000/100001 [1:13:31<28:25:44,  1.09s/it]train iter 6000
loss: 0.32310259342193604
lr: 9.486745132548673e-05



















































































































































































































  7%|▋         | 7000/100001 [1:20:42<26:14:22,  1.02s/it]train iter 7000
loss: 0.28465285897254944
lr: 0.00011067869321306785

















































































































































































































  8%|▊         | 8000/100001 [1:27:46<15:37:14,  1.64it/s]train iter 8000
loss: nan
lr: 0.000126489935100649


















































































































































































































  9%|▉         | 9000/100001 [1:34:54<15:33:25,  1.62it/s]train iter 9000
loss: nan
lr: 0.0001423011769882301




















































































































































































































 10%|▉         | 9999/100001 [1:42:03<10:53:59,  2.29it/s]
 10%|▉         | 10000/100001 [1:42:04<16:17:24,  1.53it/s]











































































































































  1%|          | 6/1000 [00:01<04:48,  3.45it/s]









































































































































100%|█████████▉| 999/1000 [04:39<00:00,  3.72it/s]
eval-test: {'loss': nan, 'last_loss': nan, 'avg_acc': 0.500720739364624, 'acc': 0.5090000033378601}
patience_left: 5
train iter 10000
loss: nan
lr: 0.00015811241887581123
 10%|█         | 10005/100001 [1:51:27<1021:56:41, 40.88s/it]





























 10%|█         | 10149/100001 [1:52:26<10:38:21,  2.35it/s]