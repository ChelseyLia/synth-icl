[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'seed' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'optimizer' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'model' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'data' was locked by 'sweep' (ignored update).
CONFIG
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 5947
â”œâ”€â”€ seed_eval
â”‚   â””â”€â”€ 2000
â”œâ”€â”€ seed_test
â”‚   â””â”€â”€ 3000
â”œâ”€â”€ device
â”‚   â””â”€â”€ cuda
â”œâ”€â”€ train
â”‚   â””â”€â”€ do: true
â”‚       do_save: false
â”‚       reset_every: null
â”‚       dtype: float32
â”‚       compile: false
â”‚       do_amp: false
â”‚       batch_size: 128
â”‚       grad_clip: 1.0
â”‚       iters: 100001
â”‚       samples: null
â”‚       log_every: 1000
â”‚       save_every: 100000
â”‚       save_path: ./out
â”‚       num_workers: 0
â”‚       do_early_stop: false
â”‚       early_stop_patience: 5
â”‚       early_stop_metric: loss
â”‚       early_stop_tol: 0.001
â”‚       early_stop_start_iter: 20000.2
â”‚       early_stop_acc: null
â”‚       parallel_loss: true
â”‚       merge_embeds: false
â”‚       merge_type: sum
â”‚
â”œâ”€â”€ eval
â”‚   â””â”€â”€ do: true
â”‚       split: both
â”‚       batch_size: 1
â”‚       every: 5000
â”‚       every_samples: null
â”‚       iters: 1000
â”‚
â”œâ”€â”€ scheduler
â”‚   â””â”€â”€ decay_lr: true
â”‚       warmup_iters: 20000.2
â”‚       lr_decay_iters: 100001
â”‚       min_lr: 0.0001
â”‚
â”œâ”€â”€ optimizer
â”‚   â””â”€â”€ lr: 0.001
â”‚       _name_: adamw
â”‚       weight_decay: 0
â”‚       betas:
â”‚       - 0.9
â”‚       - 0.95
â”‚
â”œâ”€â”€ log_level
â”‚   â””â”€â”€ info
â”œâ”€â”€ examples_to_log
â”‚   â””â”€â”€ 3
â”œâ”€â”€ log_batch_idx
â”‚   â””â”€â”€ [0, 1]
â”œâ”€â”€ wandb
â”‚   â””â”€â”€ project: icl-arch
â”‚
â”œâ”€â”€ save_checkpoints
â”‚   â””â”€â”€ False
â”œâ”€â”€ nl_icl
â”‚   â””â”€â”€ do: false
â”‚       checkpoint_path: null
â”‚       hf_path: null
â”‚       task: sentiment
â”‚       n_seeds: 10
â”‚       min_examples_per_class: 0
â”‚       max_examples_per_class: 9
â”‚       do_full_vocab: true
â”‚
â”œâ”€â”€ do_count_param_only
â”‚   â””â”€â”€ False
â”œâ”€â”€ model
â”‚   â””â”€â”€ _name_: retnet
â”‚       d_model: 64
â”‚       d_inner: 256
â”‚       n_layer: 12
â”‚       n_heads: 2.0
â”‚       n_kv_heads: 2.0
â”‚       max_seq_len: 4096
â”‚
â””â”€â”€ data
    â””â”€â”€ _name_: linear-regression
        curriculum:
          dims:
            start: 5
            end: 5
            inc: 1
            interval: 2000
          points_train:
            start: 32
            end: 32
            inc: 2
            interval: 2000
          points_val:
            start: 1024
            end: 1024
            inc: 2
            interval: 2000
        task: linear_regression
        data: gaussian
        task_kwargs: {}
        n_dims: 5
        train_noise: 0
        val_noise: 0
model.layers.0.retention.q_proj.weight: 4096
model.layers.0.retention.q_proj.bias: 64
model.layers.0.retention.k_proj.weight: 4096
model.layers.0.retention.k_proj.bias: 64
model.layers.0.retention.v_proj.weight: 8192
model.layers.0.retention.v_proj.bias: 128
model.layers.0.retention.g_proj.weight: 8192
model.layers.0.retention.g_proj.bias: 128
model.layers.0.retention.out_proj.weight: 8192
model.layers.0.retention.out_proj.bias: 64
model.layers.0.retention_layer_norm.weight: 64
model.layers.0.retention_layer_norm.bias: 64
model.layers.0.ffn.fc1.weight: 16384
model.layers.0.ffn.fc1.bias: 256
model.layers.0.ffn.fc2.weight: 16384
model.layers.0.ffn.fc2.bias: 64
model.layers.0.ffn.ffn_layernorm.weight: 256
model.layers.0.ffn.ffn_layernorm.bias: 256
model.layers.0.final_layer_norm.weight: 64
model.layers.0.final_layer_norm.bias: 64
model.layers.1.retention.q_proj.weight: 4096
model.layers.1.retention.q_proj.bias: 64
model.layers.1.retention.k_proj.weight: 4096
model.layers.1.retention.k_proj.bias: 64
model.layers.1.retention.v_proj.weight: 8192
model.layers.1.retention.v_proj.bias: 128
model.layers.1.retention.g_proj.weight: 8192
model.layers.1.retention.g_proj.bias: 128
model.layers.1.retention.out_proj.weight: 8192
model.layers.1.retention.out_proj.bias: 64
model.layers.1.retention_layer_norm.weight: 64
model.layers.1.retention_layer_norm.bias: 64
model.layers.1.ffn.fc1.weight: 16384
model.layers.1.ffn.fc1.bias: 256
model.layers.1.ffn.fc2.weight: 16384
model.layers.1.ffn.fc2.bias: 64
model.layers.1.ffn.ffn_layernorm.weight: 256
model.layers.1.ffn.ffn_layernorm.bias: 256
model.layers.1.final_layer_norm.weight: 64
model.layers.1.final_layer_norm.bias: 64
model.layers.2.retention.q_proj.weight: 4096
model.layers.2.retention.q_proj.bias: 64
model.layers.2.retention.k_proj.weight: 4096
model.layers.2.retention.k_proj.bias: 64
model.layers.2.retention.v_proj.weight: 8192
model.layers.2.retention.v_proj.bias: 128
model.layers.2.retention.g_proj.weight: 8192
model.layers.2.retention.g_proj.bias: 128
model.layers.2.retention.out_proj.weight: 8192
model.layers.2.retention.out_proj.bias: 64
model.layers.2.retention_layer_norm.weight: 64
model.layers.2.retention_layer_norm.bias: 64
model.layers.2.ffn.fc1.weight: 16384
model.layers.2.ffn.fc1.bias: 256
model.layers.2.ffn.fc2.weight: 16384
model.layers.2.ffn.fc2.bias: 64
model.layers.2.ffn.ffn_layernorm.weight: 256
model.layers.2.ffn.ffn_layernorm.bias: 256
model.layers.2.final_layer_norm.weight: 64
model.layers.2.final_layer_norm.bias: 64
model.layers.3.retention.q_proj.weight: 4096
model.layers.3.retention.q_proj.bias: 64
model.layers.3.retention.k_proj.weight: 4096
model.layers.3.retention.k_proj.bias: 64
model.layers.3.retention.v_proj.weight: 8192
model.layers.3.retention.v_proj.bias: 128
model.layers.3.retention.g_proj.weight: 8192
model.layers.3.retention.g_proj.bias: 128
model.layers.3.retention.out_proj.weight: 8192
model.layers.3.retention.out_proj.bias: 64
model.layers.3.retention_layer_norm.weight: 64
model.layers.3.retention_layer_norm.bias: 64
model.layers.3.ffn.fc1.weight: 16384
model.layers.3.ffn.fc1.bias: 256
model.layers.3.ffn.fc2.weight: 16384
model.layers.3.ffn.fc2.bias: 64
model.layers.3.ffn.ffn_layernorm.weight: 256
model.layers.3.ffn.ffn_layernorm.bias: 256
model.layers.3.final_layer_norm.weight: 64
model.layers.3.final_layer_norm.bias: 64
model.layers.4.retention.q_proj.weight: 4096
model.layers.4.retention.q_proj.bias: 64
model.layers.4.retention.k_proj.weight: 4096
model.layers.4.retention.k_proj.bias: 64
model.layers.4.retention.v_proj.weight: 8192
model.layers.4.retention.v_proj.bias: 128
model.layers.4.retention.g_proj.weight: 8192
model.layers.4.retention.g_proj.bias: 128
model.layers.4.retention.out_proj.weight: 8192
model.layers.4.retention.out_proj.bias: 64
model.layers.4.retention_layer_norm.weight: 64
model.layers.4.retention_layer_norm.bias: 64
model.layers.4.ffn.fc1.weight: 16384
model.layers.4.ffn.fc1.bias: 256
model.layers.4.ffn.fc2.weight: 16384
model.layers.4.ffn.fc2.bias: 64
model.layers.4.ffn.ffn_layernorm.weight: 256
model.layers.4.ffn.ffn_layernorm.bias: 256
model.layers.4.final_layer_norm.weight: 64
model.layers.4.final_layer_norm.bias: 64
model.layers.5.retention.q_proj.weight: 4096
model.layers.5.retention.q_proj.bias: 64
model.layers.5.retention.k_proj.weight: 4096
model.layers.5.retention.k_proj.bias: 64
model.layers.5.retention.v_proj.weight: 8192
model.layers.5.retention.v_proj.bias: 128
model.layers.5.retention.g_proj.weight: 8192
model.layers.5.retention.g_proj.bias: 128
model.layers.5.retention.out_proj.weight: 8192
model.layers.5.retention.out_proj.bias: 64
model.layers.5.retention_layer_norm.weight: 64
model.layers.5.retention_layer_norm.bias: 64
model.layers.5.ffn.fc1.weight: 16384
model.layers.5.ffn.fc1.bias: 256
model.layers.5.ffn.fc2.weight: 16384
model.layers.5.ffn.fc2.bias: 64
model.layers.5.ffn.ffn_layernorm.weight: 256
model.layers.5.ffn.ffn_layernorm.bias: 256
model.layers.5.final_layer_norm.weight: 64
model.layers.5.final_layer_norm.bias: 64
model.layers.6.retention.q_proj.weight: 4096
model.layers.6.retention.q_proj.bias: 64
model.layers.6.retention.k_proj.weight: 4096
model.layers.6.retention.k_proj.bias: 64
model.layers.6.retention.v_proj.weight: 8192
model.layers.6.retention.v_proj.bias: 128
model.layers.6.retention.g_proj.weight: 8192
model.layers.6.retention.g_proj.bias: 128
model.layers.6.retention.out_proj.weight: 8192
model.layers.6.retention.out_proj.bias: 64
model.layers.6.retention_layer_norm.weight: 64
model.layers.6.retention_layer_norm.bias: 64
model.layers.6.ffn.fc1.weight: 16384
model.layers.6.ffn.fc1.bias: 256
model.layers.6.ffn.fc2.weight: 16384
model.layers.6.ffn.fc2.bias: 64
model.layers.6.ffn.ffn_layernorm.weight: 256
model.layers.6.ffn.ffn_layernorm.bias: 256
model.layers.6.final_layer_norm.weight: 64
model.layers.6.final_layer_norm.bias: 64
model.layers.7.retention.q_proj.weight: 4096
model.layers.7.retention.q_proj.bias: 64
model.layers.7.retention.k_proj.weight: 4096
model.layers.7.retention.k_proj.bias: 64
model.layers.7.retention.v_proj.weight: 8192
model.layers.7.retention.v_proj.bias: 128
model.layers.7.retention.g_proj.weight: 8192
model.layers.7.retention.g_proj.bias: 128
model.layers.7.retention.out_proj.weight: 8192
model.layers.7.retention.out_proj.bias: 64
model.layers.7.retention_layer_norm.weight: 64
model.layers.7.retention_layer_norm.bias: 64
model.layers.7.ffn.fc1.weight: 16384
model.layers.7.ffn.fc1.bias: 256
model.layers.7.ffn.fc2.weight: 16384
model.layers.7.ffn.fc2.bias: 64
model.layers.7.ffn.ffn_layernorm.weight: 256
model.layers.7.ffn.ffn_layernorm.bias: 256
model.layers.7.final_layer_norm.weight: 64
model.layers.7.final_layer_norm.bias: 64
model.layers.8.retention.q_proj.weight: 4096
model.layers.8.retention.q_proj.bias: 64
model.layers.8.retention.k_proj.weight: 4096
model.layers.8.retention.k_proj.bias: 64
model.layers.8.retention.v_proj.weight: 8192
model.layers.8.retention.v_proj.bias: 128
model.layers.8.retention.g_proj.weight: 8192
model.layers.8.retention.g_proj.bias: 128
model.layers.8.retention.out_proj.weight: 8192
model.layers.8.retention.out_proj.bias: 64
model.layers.8.retention_layer_norm.weight: 64
model.layers.8.retention_layer_norm.bias: 64
model.layers.8.ffn.fc1.weight: 16384
model.layers.8.ffn.fc1.bias: 256
model.layers.8.ffn.fc2.weight: 16384
model.layers.8.ffn.fc2.bias: 64
model.layers.8.ffn.ffn_layernorm.weight: 256
model.layers.8.ffn.ffn_layernorm.bias: 256
model.layers.8.final_layer_norm.weight: 64
model.layers.8.final_layer_norm.bias: 64
model.layers.9.retention.q_proj.weight: 4096
model.layers.9.retention.q_proj.bias: 64
model.layers.9.retention.k_proj.weight: 4096
model.layers.9.retention.k_proj.bias: 64
model.layers.9.retention.v_proj.weight: 8192
model.layers.9.retention.v_proj.bias: 128
model.layers.9.retention.g_proj.weight: 8192
model.layers.9.retention.g_proj.bias: 128
model.layers.9.retention.out_proj.weight: 8192
model.layers.9.retention.out_proj.bias: 64
model.layers.9.retention_layer_norm.weight: 64
model.layers.9.retention_layer_norm.bias: 64
model.layers.9.ffn.fc1.weight: 16384
model.layers.9.ffn.fc1.bias: 256
model.layers.9.ffn.fc2.weight: 16384
model.layers.9.ffn.fc2.bias: 64
model.layers.9.ffn.ffn_layernorm.weight: 256
model.layers.9.ffn.ffn_layernorm.bias: 256
model.layers.9.final_layer_norm.weight: 64
model.layers.9.final_layer_norm.bias: 64
model.layers.10.retention.q_proj.weight: 4096
model.layers.10.retention.q_proj.bias: 64
model.layers.10.retention.k_proj.weight: 4096
model.layers.10.retention.k_proj.bias: 64
model.layers.10.retention.v_proj.weight: 8192
model.layers.10.retention.v_proj.bias: 128
model.layers.10.retention.g_proj.weight: 8192
model.layers.10.retention.g_proj.bias: 128
model.layers.10.retention.out_proj.weight: 8192
model.layers.10.retention.out_proj.bias: 64
model.layers.10.retention_layer_norm.weight: 64
model.layers.10.retention_layer_norm.bias: 64
model.layers.10.ffn.fc1.weight: 16384
model.layers.10.ffn.fc1.bias: 256
model.layers.10.ffn.fc2.weight: 16384
model.layers.10.ffn.fc2.bias: 64
model.layers.10.ffn.ffn_layernorm.weight: 256
model.layers.10.ffn.ffn_layernorm.bias: 256
model.layers.10.final_layer_norm.weight: 64
model.layers.10.final_layer_norm.bias: 64
model.layers.11.retention.q_proj.weight: 4096
model.layers.11.retention.q_proj.bias: 64
model.layers.11.retention.k_proj.weight: 4096
model.layers.11.retention.k_proj.bias: 64
model.layers.11.retention.v_proj.weight: 8192
model.layers.11.retention.v_proj.bias: 128
model.layers.11.retention.g_proj.weight: 8192
model.layers.11.retention.g_proj.bias: 128
model.layers.11.retention.out_proj.weight: 8192
model.layers.11.retention.out_proj.bias: 64
model.layers.11.retention_layer_norm.weight: 64
model.layers.11.retention_layer_norm.bias: 64
model.layers.11.ffn.fc1.weight: 16384
model.layers.11.ffn.fc1.bias: 256
model.layers.11.ffn.fc2.weight: 16384
model.layers.11.ffn.fc2.bias: 64
model.layers.11.ffn.ffn_layernorm.weight: 256
model.layers.11.ffn.ffn_layernorm.bias: 256
model.layers.11.final_layer_norm.weight: 64
model.layers.11.final_layer_norm.bias: 64
model.layer_norm.weight: 64
model.layer_norm.bias: 64
n_params=804992
ignored=[('embedder.embedder.weight', 320), ('embedder.embedder.bias', 64), ('head.head.weight', 64)]
  0%|                                                                                                                                  | 0/100001 [00:00<?, ?it/s]
  0%|                                                                                                                                    | 0/1000 [00:00<?, ?it/s]
[[split=train]] train_iter: 0, batch_idx: 0, input: [[-1.7218033075332642, -0.500533401966095, 0.6593334078788757, 0.267077773809433, -0.31861087679862976], [2.196141481399536, 0.0, 0.0, 0.0, 0.0], [0.817406177520752, -0.03669105842709541, -0.17603135108947754, 0.970534086227417, 0.20161357522010803], [-2.441826581954956, 0.0, 0.0, 0.0, 0.0], [-0.2251984179019928, -0.055584900081157684, 0.33051490783691406, -0.38168269395828247, -0.1642618328332901], [1.0629550218582153, 0.0, 0.0, 0.0, 0.0], [0.07214709371328354, -0.2076098918914795, 1.7032774686813354, 0.9354321360588074, 1.276244044303894], [1.3611150979995728, 0.0, 0.0, 0.0, 0.0], [0.8153160810470581, -0.02592933177947998, -0.574684202671051, 1.0587936639785767, -0.7576869130134583], [-3.4467387199401855, 0.0, 0.0, 0.0, 0.0]], target: [2.196141481399536, -2.441826581954956, 1.0629550218582153, 1.3611150979995728, -3.4467387199401855, 0.17520570755004883, -0.5723229050636292, 0.5247389078140259, 1.8495161533355713, -0.7767629623413086]
[[split=train]] train_iter: 0, batch_idx: 1, input: [[-0.12389004230499268, 0.9711284041404724, 0.9113059043884277, -1.451625943183899, -0.059167321771383286], [0.09475922584533691, 0.0, 0.0, 0.0, 0.0], [-0.1884264498949051, -0.8413199186325073, -1.7426292896270752, -0.2622719705104828, 0.8166283965110779], [-5.370824813842773, 0.0, 0.0, 0.0, 0.0], [0.6010450720787048, 1.012108325958252, 1.0374581813812256, 0.047752745449543, 0.754387378692627], [5.433032989501953, 0.0, 0.0, 0.0, 0.0], [-1.8359019756317139, -1.6708252429962158, -0.47474750876426697, -0.8790744543075562, 0.09896060824394226], [-9.654635429382324, 0.0, 0.0, 0.0, 0.0], [2.021898031234741, 0.8616278171539307, 0.5329847931861877, -0.8685665726661682, 0.8290926218032837], [4.307877063751221, 0.0, 0.0, 0.0, 0.0]], target: [0.09475922584533691, -5.370824813842773, 5.433032989501953, -9.654635429382324, 4.307877063751221, 3.973325252532959, 3.152841329574585, 2.054338216781616, -1.9944877624511719, -1.0851516723632812]

  0%|                                                                                                                          | 1/1000 [00:04<1:08:22,  4.11s/it]
[[split=eval]] train_iter: 0, eval_iter: 1, batch_idx: 0, input: [[0.32853397727012634, -1.113255262374878, 0.838888943195343, -0.6574654579162598, -0.3239317536354065], [1.1324061155319214, 0.0, 0.0, 0.0, 0.0], [1.142399787902832, -0.038401633501052856, 1.4896352291107178, 0.07022134214639664, -1.397045373916626], [-1.6001558303833008, 0.0, 0.0, 0.0, 0.0], [1.96773362159729, 0.31781065464019775, -1.793107509613037, 0.3199353814125061, -0.9854117631912231], [0.5978349447250366, 0.0, 0.0, 0.0, 0.0], [-1.1753662824630737, -0.7069042921066284, 1.631754994392395, 0.33515477180480957, 0.7220890522003174], [-0.8600477576255798, 0.0, 0.0, 0.0, 0.0], [-0.14661362767219543, -1.3920907974243164, -0.6477355360984802, -0.11829765141010284, -1.3703991174697876], [-0.6125239133834839, 0.0, 0.0, 0.0, 0.0]], target: [1.1324061155319214, -1.6001558303833008, 0.5978349447250366, -0.8600477576255798, -0.6125239133834839, 5.261972427368164, 3.258908748626709, 0.8352506160736084, 1.506016492843628, 2.41762113571167]













  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                   | 58/1000 [00:29<07:19,  2.14it/s]